---
title: Integrations
description: LangChain.dart integrates with various LLM providers, embedding services, and vector stores.
previous: /modules/agents/toolkits/toolkits
previousTitle: Toolkits
---

# Integrations

LangChain.dart provides integrations with a variety of providers for chat models, LLMs, embeddings, and vector stores.

## Chat Models

Build conversational AI applications with these chat model providers:

<CardGroup cols={3}>
  <Card title="OpenAI" icon="message" href="/integrations/openai">
    GPT-4, GPT-3.5-turbo, and more
  </Card>
  <Card title="Google AI" icon="google" href="/integrations/googleai">
    Gemini models via Google AI Studio
  </Card>
  <Card title="Firebase Vertex AI" icon="fire" href="/integrations/firebase_vertex_ai">
    Gemini via Firebase for mobile apps
  </Card>
  <Card title="Anthropic" icon="brain" href="/integrations/anthropic">
    Claude models
  </Card>
  <Card title="Ollama" icon="server" href="/integrations/ollama">
    Run LLMs locally
  </Card>
  <Card title="Mistral AI" icon="bolt" href="/integrations/mistralai">
    Mistral and Mixtral models
  </Card>
</CardGroup>

### More Chat Models

- [GCP Vertex AI](/integrations/gcp_vertex_ai) - Google Cloud's Vertex AI
- [OpenRouter](/integrations/open_router) - Access multiple models via one API
- [Together AI](/integrations/together_ai) - Open-source models
- [Anyscale](/integrations/anyscale) - Scalable inference
- [Prem](/integrations/prem) - Self-hosted AI infrastructure

## Getting Started

Choose an integration above to see detailed setup instructions and code examples.
