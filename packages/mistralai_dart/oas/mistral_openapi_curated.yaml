openapi: 3.0.0

info:
  title: Mistral AI API
  description: API Spec for Mistral API. Please see https://docs.mistral.ai/api for more details.
  version: 0.0.2

servers:
  - url: https://api.mistral.ai/v1
    description: Mistral AI server URL

tags:
  - name: Chat
    description: Given a list of messages comprising a conversation, the model will return a response.
  - name: Embeddings
    description: Get a vector representation of a given input.
  - name: Models
    description: List and describe the various models available.

paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: Create Chat Completions.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
  /embeddings:
    post:
      operationId: createEmbedding
      tags:
        - Embeddings
      summary: Create Embeddings.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingResponse'
  /models:
    get:
      operationId: listModels
      tags:
        - Models
      summary: List Available Models.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelList'

components:

  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: 'bearer'

  schemas:
    ChatCompletionRequest:
      type: object
      description: Request class for the chat completion endpoint.
      properties:
        model:
          title: ChatCompletionModel
          description: >
            ID of the model to use. You can use the [List Available
            Models](https://docs.mistral.ai/api#operation/listModels) API to see all of your available
            models, or see our [Model overview](https://docs.mistral.ai/models) for model descriptions.
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ChatCompletionModels
              description: |
                Available chat completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                - mistral-large-latest
                - mistral-small-latest
                - codestral-latest
                - ministral-3b-latest
                - ministral-8b-latest
                - open-mistral-nemo
                - pixtral-large-latest
        messages:
          description: >
            The prompt(s) to generate completions for, encoded as a list of dict
            with role and content. The first prompt role should be `user` or
            `system`.
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessage'
        temperature:
          type: number
          minimum: 0
          maximum: 1.5
          nullable: true
          description: >
            What sampling temperature to use, between 0.0 and 1.5. Higher values
            like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.


            We generally recommend altering this or `top_p` but not both.
        top_p:
          type: number
          minimum: 0
          maximum: 1
          nullable: true
          description: >
            Nucleus sampling, where the model considers the results of the
            tokens with `top_p` probability mass. So 0.1 means only the tokens
            comprising the top 10% probability mass are considered.


            We generally recommend altering this or `temperature` but not both.
        max_tokens:
          type: integer
          minimum: 0
          nullable: true
          description: >
            The maximum number of tokens to generate in the completion.


            The token count of your prompt plus `max_tokens` cannot exceed the
            model's context length.
        stream:
          type: boolean
          nullable: true
          description: >
            Whether to stream back partial progress. If set, tokens will be sent
            as data-only server-sent events as they become available, with the
            stream terminated by a data: [DONE] message. Otherwise, the server
            will hold the request open until the timeout or until completion,
            with the response containing the full result as JSON.
        stop:
          title: ChatCompletionStop
          description: |
            Stop generation if this token is detected, or if the end of the sequence is detected.
          anyOf:
            - type: string
              description: A single stop string.
            - type: array
              description: A list of stop strings.
              items:
                type: string
          nullable: true
        random_seed:
          type: integer
          default: null
          nullable: true
          description: >
            The seed to use for random sampling. If set, different calls will
            generate deterministic results.
        response_format:
          $ref: '#/components/schemas/ResponseFormat'
        tools:
          type: array
          items:
            $ref: '#/components/schemas/Tool'
          nullable: true
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool.
            Use this to provide a list of functions the model may generate JSON inputs for.
        tool_choice:
          title: ChatCompletionToolChoice
          description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tool and instead generates a message.
            `auto` means the model can pick between generating a message or calling one or more tools.
            `any` means the model must call one or more tools.
            `required` is an alias for `any`.
            Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}`
            forces the model to call that tool.
          nullable: true
          anyOf:
            - type: string
              title: ChatCompletionToolChoiceOption
              description: |
                Controls which (if any) tool is called by the model.
              enum:
                - none
                - auto
                - any
                - required
            - $ref: '#/components/schemas/ToolChoiceTool'
        presence_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          nullable: true
          description: |
            Positive values penalize new tokens based on whether they appear in the text so far,
            increasing the model's likelihood to talk about new topics.
        frequency_penalty:
          type: number
          minimum: -2.0
          maximum: 2.0
          nullable: true
          description: |
            Positive values penalize new tokens based on their existing frequency in the text so far,
            decreasing the model's likelihood to repeat the same line verbatim.
        n:
          type: integer
          minimum: 1
          nullable: true
          description: |
            Number of completions to return for each request.
        parallel_tool_calls:
          type: boolean
          nullable: true
          default: true
          description: |
            Whether to enable parallel function calling during tool use.
        safe_prompt:
          type: boolean
          nullable: true
          description: |
            Whether to inject a safety prompt before all conversations.
        metadata:
          type: object
          additionalProperties: true
          nullable: true
          description: |
            Custom metadata to associate with the request.
        prediction:
          $ref: '#/components/schemas/Prediction'
        prompt_mode:
          $ref: '#/components/schemas/MistralPromptMode'
      required:
        - model
        - messages
    ChatCompletionResponse:
      type: object
      description: Response class for the chat completion endpoint.
      properties:
        id:
          type: string
          description: The unique identifier for this completion.
          example: cmpl-e5cc70bb28c444948073e77776eb30ef
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          example: chat.completion
        created:
          type: integer
          description: The timestamp of when this completion was created.
          example: 1702256327
        model:
          type: string
          description: The model used for this completion.
          example: mistral-tiny
        choices:
          type: array
          description: The list of choices for this completion.
          items:
            type: object
            title: ChatCompletionChoice
            description: A choice in a chat completion.
            required:
              - index
              - message
              - finish_reason
            properties:
              index:
                type: integer
                description: The index of this choice.
                example: 0
              message:
                $ref: '#/components/schemas/AssistantMessage'
              finish_reason:
                $ref: '#/components/schemas/ChatCompletionFinishReason'
        usage:
          $ref: '#/components/schemas/ChatCompletionUsage'
      required:
        - id
        - object
        - created
        - model
        - choices
        - usage
    ChatCompletionMessage:
      type: object
      description: A message in a chat conversation.
      properties:
        role:
          $ref: '#/components/schemas/ChatCompletionMessageRole'
        content:
          type: string
          description: The message content.
          example: What is the best French cheese?
          nullable: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          nullable: true
          description: |
            The tool calls generated by the model, such as function calls.
        tool_call_id:
          type: string
          nullable: true
          description: |
            Tool call that this message is responding to (for tool messages).
        name:
          type: string
          nullable: true
          description: |
            The name of the tool that was called (for tool messages).
        prefix:
          type: boolean
          nullable: true
          description: |
            Set this to true when adding an assistant message as a prefix for the next completion.
      required:
        - role
    AssistantMessage:
      type: object
      description: A message from the assistant in a chat conversation.
      properties:
        role:
          type: string
          enum:
            - assistant
          description: The role of the message, which is always `assistant`.
        content:
          type: string
          description: The message content.
          nullable: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          nullable: true
          description: |
            The tool calls generated by the model, such as function calls.
        prefix:
          type: boolean
          nullable: true
          description: |
            Set this to true when adding an assistant message as a prefix for the next completion.
    ChatCompletionMessageRole:
      type: string
      enum:
        - system
        - user
        - assistant
        - tool
      description: The role of the message.
      example: user
    ChatCompletionFinishReason:
      type: string
      enum:
        - stop
        - length
        - model_length
        - error
        - tool_calls
      description: The reason the model stopped generating tokens.
      example: stop
    ChatCompletionUsage:
      type: object
      description: The usage statistics for this completion.
      properties:
        prompt_tokens:
          type: integer
          description: The number of tokens in the prompt.
          example: 14
        completion_tokens:
          type: integer
          description: The number of tokens in the completion.
          example: 93
        total_tokens:
          type: integer
          description: The total number of tokens generated.
          example: 107
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    ChatCompletionStreamResponse:
      type: object
      description: Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: The unique identifier for this completion.
          example: cmpl-e5cc70bb28c444948073e77776eb30ef
        object:
          type: string
          description: The object type, which is always `chat.completion.chunk`.
          example: chat.completion.chunk
        created:
          type: integer
          description: The timestamp of when this completion was created.
          example: 1702256327
        model:
          type: string
          description: The model used for this completion.
          example: mistral-tiny
        choices:
          type: array
          description: The list of choices for this completion.
          items:
            type: object
            title: ChatCompletionStreamChoice
            description: A choice in a chat completion stream.
            required:
              - index
              - delta
            properties:
              index:
                type: integer
                description: The index of this choice.
                example: 0
              delta:
                $ref: '#/components/schemas/ChatCompletionStreamDelta'
              finish_reason:
                $ref: '#/components/schemas/ChatCompletionFinishReason'
        usage:
          $ref: '#/components/schemas/ChatCompletionUsage'
          description: |
            Token usage statistics for this completion. Only present in the final chunk of a streaming response.
      required:
        - id
        - model
        - choices
    ChatCompletionStreamDelta:
      type: object
      description: A chat completion delta generated by streamed model responses.
      properties:
        role:
          $ref: '#/components/schemas/ChatCompletionMessageRole'
        content:
          type: string
          description: The message content.
          example: What is the best French cheese?
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          nullable: true
          description: |
            The tool calls generated by the model, such as function calls.

    # Tool/Function Calling Schemas
    Tool:
      type: object
      description: A tool the model may call.
      properties:
        type:
          $ref: '#/components/schemas/ToolType'
        function:
          $ref: '#/components/schemas/FunctionDefinition'
      required:
        - type
        - function
    ToolType:
      type: string
      description: The type of the tool.
      enum:
        - function
    FunctionDefinition:
      type: object
      description: A function that the model may call.
      properties:
        name:
          type: string
          description: |
            The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes,
            with a maximum length of 64.
        description:
          type: string
          nullable: true
          description: |
            A description of what the function does, used by the model to choose when and how to call the function.
        parameters:
          type: object
          additionalProperties: true
          description: |
            The parameters the functions accepts, described as a JSON Schema object.
            Omitting parameters defines a function with an empty parameter list.
      required:
        - name
        - parameters
    ToolCall:
      type: object
      description: A tool call made by the model.
      properties:
        id:
          type: string
          nullable: true
          description: The unique identifier of the tool call.
        type:
          type: string
          enum:
            - function
          nullable: true
          description: The type of the tool (currently only 'function').
        function:
          $ref: '#/components/schemas/FunctionCall'
          nullable: true
          description: The function call details.
        index:
          type: integer
          nullable: true
          description: The index of the tool call in the list of tool calls.
    FunctionCall:
      type: object
      description: A function call made by the model.
      properties:
        name:
          type: string
          nullable: true
          description: The name of the function to call.
        arguments:
          type: string
          nullable: true
          description: |
            The arguments to call the function with, as generated by the model in JSON format.
    ToolChoiceTool:
      type: object
      description: Forces the model to call a specific tool.
      properties:
        type:
          $ref: '#/components/schemas/ToolType'
        function:
          $ref: '#/components/schemas/ToolChoiceToolFunction'
      required:
        - type
        - function
    ToolChoiceToolFunction:
      type: object
      description: The function to force the model to call.
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name

    # Response Format Schemas
    ResponseFormat:
      type: object
      description: |
        An object specifying the format that the model must output.
        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message
        the model generates is valid JSON.
        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs
        which guarantees the model will match your supplied JSON schema.
      nullable: true
      properties:
        type:
          $ref: '#/components/schemas/ResponseFormatType'
        json_schema:
          $ref: '#/components/schemas/JsonSchema'
    ResponseFormatType:
      type: string
      description: The type of response format.
      enum:
        - text
        - json_object
        - json_schema
    JsonSchema:
      type: object
      description: The JSON schema for structured output.
      nullable: true
      properties:
        name:
          type: string
          description: The name of the response format.
        description:
          type: string
          nullable: true
          description: A description of the response format.
        schema:
          type: object
          additionalProperties: true
          description: The JSON schema object.
        strict:
          type: boolean
          nullable: true
          description: Whether to enable strict schema adherence.
      required:
        - name
        - schema

    # Prediction/Reasoning Schemas
    Prediction:
      type: object
      description: |
        A prediction object used to provide expected output for the model.
        This can help reduce latency by allowing the model to skip generating tokens
        that match the prediction.
      nullable: true
      properties:
        type:
          type: string
          description: The type of prediction, currently only 'content' is supported.
          enum:
            - content
        content:
          type: string
          description: The predicted content that the model should generate.
      required:
        - type
        - content
    MistralPromptMode:
      type: string
      description: |
        The prompt mode to use for the request.
        Use 'reasoning' to enable reasoning mode for supported models.
      nullable: true
      enum:
        - reasoning

    # Embedding Schemas
    EmbeddingRequest:
      type: object
      description: Request class for the embedding endpoint.
      properties:
        model:
          title: EmbeddingModel
          description: >
            ID of the model to use. You can use the [List Available
            Models](https://docs.mistral.ai/api#operation/listModels) API to see all of your available
            models, or see our [Model overview](https://docs.mistral.ai/models) for model descriptions.
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: EmbeddingModels
              description: |
                Available embedding models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                - mistral-embed
                - codestral-embed-2505
        input:
          type: array
          items:
            type: string
          example:
            - Hello
            - world
          description: |
            The list of strings to embed.
        output_dimension:
          type: integer
          nullable: true
          description: |
            The number of dimensions the resulting output embeddings should have.
            Only supported by certain models (e.g., codestral-embed-2505).
        output_dtype:
          type: string
          title: EmbeddingOutputDtype
          enum:
            - float
            - int8
            - uint8
            - binary
            - ubinary
          nullable: true
          description: |
            The data type of the output embeddings.
        encoding_format:
          type: string
          title: EmbeddingEncodingFormat
          enum:
            - float
            - base64
          nullable: true
          description: |
            The format of the output data.
      required:
        - model
        - input
    EmbeddingResponse:
      type: object
      description: Response class for the embedding endpoint.
      properties:
        id:
          type: string
          description: The unique identifier for this embedding response.
          example: embd-aad6fc62b17349b192ef09225058bc45
        object:
          type: string
          description: The object type, which is always `list`.
          example: list
        data:
          type: array
          description: The list of embeddings.
          items:
            $ref: '#/components/schemas/Embedding'
        model:
          type: string
          description: The model used for this embedding.
        created:
          type: integer
          nullable: true
          description: Unix timestamp when the response was created.
        usage:
          type: object
          title: EmbeddingUsage
          description: The usage statistics for this embedding.
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens in the prompt.
              example: 9
            completion_tokens:
              type: integer
              description: The number of completion tokens (typically 0 for embeddings).
              example: 0
            total_tokens:
              type: integer
              description: The total number of tokens.
              example: 9
            prompt_audio_seconds:
              type: integer
              nullable: true
              description: Duration of audio input in seconds (if applicable).
          required:
            - prompt_tokens
            - completion_tokens
            - total_tokens
      required:
        - id
        - object
        - data
        - model
        - usage
    Embedding:
      type: object
      description: A generated embedding.
      properties:
        object:
          type: string
          description: The object type, which is always `embedding`.
          example: embedding
        embedding:
          type: array
          description: The embedding vector.
          items:
            type: number
          example:
            - 0.1
            - 0.2
            - 0.3
        index:
          type: integer
          description: The index of this embedding.
          example: 0
      required:
        - object
        - embedding
        - index
    ModelList:
      type: object
      description: Response class for the list models endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
        data:
          type: array
          description: The list of models.
          items:
            $ref: '#/components/schemas/Model'
      required:
        - object
        - data
    Model:
      type: object
      description: A model.
      properties:
        id:
          type: string
          description: The unique identifier for this model.
        object:
          type: string
          description: The object type, which is always `model`.
        created:
          type: integer
          description: The timestamp of when this model was created.
        owned_by:
          type: string
          description: The organization who owns this model.
      required:
        - id
        - object
        - created
        - owned_by

security:
  - ApiKeyAuth: [ ]
