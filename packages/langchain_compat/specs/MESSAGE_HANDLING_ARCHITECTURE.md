# Message Handling Architecture

This document specifies how messages are structured and transformed across the Agent and Mapper layers in the LangChain Dart compatibility layer.

## Table of Contents
1. [Core Principles](#core-principles)
2. [Agent Layer Message Semantics](#agent-layer-message-semantics)
3. [Collecting Full History](#collecting-full-history)
4. [Provider-Specific Requirements](#provider-specific-requirements)
5. [Mapper Transformations](#mapper-transformations)
6. [Implementation Examples](#implementation-examples)

## Core Principles

### Clean Separation of Concerns

1. **Agent Layer**: Maintains clean request/response semantics
   - User messages and model messages alternate in pairs
   - One model message with multiple tool calls → One user message with multiple tool results
   - No provider-specific logic

2. **Mapper Layer**: Handles all provider-specific transformations
   - Converts Agent's clean message structure to provider requirements
   - Each provider's mapper adapts to that provider's API expectations

## Agent Layer Message Semantics

The Agent layer maintains a consistent conversation structure:

```
User: Initial prompt
Model: Response with tool calls [toolCall1, toolCall2, toolCall3]
User: Tool results [result1, result2, result3]  // Single message with all results
Model: Final synthesis response
```

### Key Rules

1. **Request/Response Pairs**: Messages always alternate between user and model
2. **Tool Result Consolidation**: All tool results from a single round are consolidated into one user message
3. **Multiple Parts**: A single message can contain multiple parts (text, tool calls, tool results)
4. **No Provider Logic**: The Agent doesn't know or care about provider-specific requirements
5. **Complete Message History**: The Agent's `run()` method returns ALL messages from the conversation, including tool interactions, regardless of whether `outputSchema` is provided

## Collecting Full History

The Agent's runXxx methods return ChatResult objects that contain both the new text and new messages generated during that specific invocation. This design parallels how the methods work:
- Just as runXxx returns only the NEW text generated by the model (not the entire conversation text)
- runXxx returns only the NEW messages generated during that run (not the entire conversation history)

### Non-Streaming Pattern (run, runFor)

```dart
// Initial conversation
final result1 = await agent.run('Hello');
// result1.output contains: "Hi! How can I help?"
// result1.messages contains: [user: "Hello", model: "Hi! How can I help?"]

// Continue conversation - pass previous messages as history
final result2 = await agent.run(
  'What is 2+2?', 
  history: result1.messages,
);
// result2.output contains: "2+2 equals 4"
// result2.messages contains: [user: "What is 2+2?", model: "2+2 equals 4"]

// Full conversation history
final fullHistory = [...result1.messages, ...result2.messages];
```

### Streaming Pattern (runStream)

```dart
// Collect messages during streaming
final messages = <ChatMessage>[];
final textBuffer = StringBuffer();

await for (final chunk in agent.runStream('Call my tools please')) {
  textBuffer.write(chunk.output);  // Accumulate text chunks
  messages.addAll(chunk.messages); // Accumulate message chunks
}

// After streaming completes:
// textBuffer.toString() contains the full text response
// messages contains all messages from this run (user prompt, tool calls, tool results, final response)
```

### Key Principles

1. **Incremental Results**: Each ChatResult contains only NEW content from that specific run
2. **Manual History Management**: Applications must maintain conversation history by accumulating messages
3. **Consistent Pattern**: Both streaming and non-streaming follow the same incremental pattern
4. **Tool Messages Included**: When tools are called, all intermediate messages (tool calls and results) are included in the returned messages

### Example: Multi-Turn Conversation with Tools

```dart
final agent = Agent('openai:gpt-4o-mini', tools: [weatherTool, timeTool]);
final conversationHistory = <ChatMessage>[];

// Turn 1: Simple question
final result1 = await agent.run('Hello!');
conversationHistory.addAll(result1.messages);
// History now: [user: "Hello!", model: "Hi! How can I help?"]

// Turn 2: Tool calling
final result2 = await agent.run(
  'What is the weather and time in NYC?',
  history: conversationHistory,
);
conversationHistory.addAll(result2.messages);
// result2.messages contains:
// - user: "What is the weather and time in NYC?"
// - model: [tool calls for weather and time]
// - user: [tool results]
// - model: "It's 72°F and 3:45 PM in NYC"

// Turn 3: Follow-up
final result3 = await agent.run(
  'Is that good weather for a walk?',
  history: conversationHistory,
);
conversationHistory.addAll(result3.messages);
// Full conversation maintained with proper context
```

## Provider-Specific Requirements

Different providers have different API requirements:

### OpenAI
- **Requirement**: Each tool result must be a separate message
- **Format**: Multiple consecutive user messages, each with role="tool"
- **Example**:
  ```
  {"role": "assistant", "tool_calls": [{"id": "1", ...}, {"id": "2", ...}]}
  {"role": "tool", "tool_call_id": "1", "content": "result1"}
  {"role": "tool", "tool_call_id": "2", "content": "result2"}
  ```

### Anthropic
- **Requirement**: Tool results can be in a single user message
- **Format**: One user message with multiple tool_result blocks
- **Example**:
  ```
  {"role": "assistant", "content": [{"type": "tool_use", "id": "1"}, {"type": "tool_use", "id": "2"}]}
  {"role": "user", "content": [{"type": "tool_result", "tool_use_id": "1"}, {"type": "tool_result", "tool_use_id": "2"}]}
  ```

### Google/Gemini
- **Requirement**: Function responses in a single message
- **Format**: One message with multiple function response parts

### Ollama
- **Requirement**: Varies by endpoint (native vs OpenAI-compatible)
- **Format**: Adapts based on endpoint type

## Mapper Transformations

Each mapper transforms the Agent's message structure to match provider requirements:

### OpenAI Mapper

```dart
// Agent sends: One user message with multiple tool results
ChatMessage(
  role: MessageRole.user,
  parts: [
    ToolPart.result(id: "1", name: "tool1", result: "..."),
    ToolPart.result(id: "2", name: "tool2", result: "..."),
  ]
)

// Mapper transforms to: Multiple tool messages
[
  ChatCompletionMessage.tool(toolCallId: "1", content: "..."),
  ChatCompletionMessage.tool(toolCallId: "2", content: "..."),
]
```

### Anthropic Mapper

```dart
// Agent sends: One user message with multiple tool results
ChatMessage(
  role: MessageRole.user,
  parts: [
    ToolPart.result(id: "1", name: "tool1", result: "..."),
    ToolPart.result(id: "2", name: "tool2", result: "..."),
  ]
)

// Mapper transforms to: Single user message with multiple content blocks
Message(
  role: MessageRole.user,
  content: [
    ContentBlock.toolResult(toolUseId: "1", content: "..."),
    ContentBlock.toolResult(toolUseId: "2", content: "..."),
  ]
)
```

## Implementation Examples

### Agent Layer (Universal)

```dart
// Execute all tools and collect results
final toolResultParts = <Part>[];
for (final toolPart in toolCalls) {
  final result = await tool.invoke(args);
  toolResultParts.add(
    ToolPart.result(
      id: toolPart.id,
      name: toolPart.name,
      result: resultString,
    ),
  );
}

// Create a single user message with all tool results
final toolResultMessage = ChatMessage(
  role: MessageRole.user,
  parts: toolResultParts,
);

// Add to history and yield
conversationHistory.add(toolResultMessage);
yield ChatResult(messages: [toolResultMessage]);
```

### OpenAI Mapper (Provider-Specific)

```dart
ChatCompletionMessage _mapUserMessage(ChatMessage message) {
  final toolResults = MessagePartHelpers.extractToolResults(message.parts);
  
  if (toolResults.isNotEmpty) {
    // OpenAI requires separate tool messages
    // This is handled by returning multiple messages from the mapper
    // (Implementation detail: caller must handle message expansion)
    final toolResult = toolResults.first;
    return ChatCompletionMessage.tool(
      toolCallId: toolResult.id,
      content: ToolResultHelpers.serialize(toolResult.result),
    );
  }
  
  // Regular user message handling...
}
```

## Key Design Benefits

1. **Clean Architecture**: Agent maintains simple, consistent message structure
2. **Provider Flexibility**: Each mapper handles its provider's specific requirements
3. **Easy Testing**: Agent behavior is predictable and provider-agnostic
4. **Future Proof**: New providers can be added without changing Agent logic
5. **Clear Semantics**: Request/response pairs make conversation flow obvious

## Migration Notes

- Previously, tool result consolidation was attempted at the Agent level
- This violated the separation of concerns and caused OpenAI compatibility issues
- The fix: Keep Agent semantics clean, let mappers handle provider requirements
- Bug fix: Agent.run() was only returning accumulated messages when outputSchema was provided; now it always returns all messages including tool interactions