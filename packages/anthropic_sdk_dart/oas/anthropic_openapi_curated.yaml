openapi: 3.0.3

info:
  title: Anthropic API
  description: API Spec for Anthropic API. Please see https://docs.anthropic.com/en/api for more details.
  version: "1"

servers:
  - url: https://api.anthropic.com/v1

tags:
  - name: Messages
    description: Send a structured list of input messages with text and/or image content, and the model will generate the next message in the conversation.

paths:
  /messages:
    post:
      operationId: createMessage
      tags:
        - Messages
      summary: Create a Message
      description: |
        Send a structured list of input messages with text and/or image content, and the
        model will generate the next message in the conversation.

        The Messages API can be used for either single queries or stateless multi-turn
        conversations.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateMessageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Message"
components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: x-api-key

  schemas:
    CreateMessageRequest:
      type: object
      description: The request parameters for creating a message.
      properties:
        model:
          title: Model
          description: |
            The model that will complete your prompt.

            See [models](https://docs.anthropic.com/en/docs/models-overview) for additional
            details and options.
          example: "claude-3-opus-20240229"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: Models
              description: |
                Available models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                - claude-3-opus-20240229
                - claude-3-sonnet-20240229
                - claude-3-haiku-20240307
                - claude-2.1
                - claude-2.0
                - claude-instant-1.2
        messages:
          type: array
          description: |
            Input messages.

            Our models are trained to operate on alternating `user` and `assistant`
            conversational turns. When creating a new `Message`, you specify the prior
            conversational turns with the `messages` parameter, and the model then generates
            the next `Message` in the conversation.

            Each input message must be an object with a `role` and `content`. You can
            specify a single `user`-role message, or you can include multiple `user` and
            `assistant` messages. The first message must always use the `user` role.

            If the final message uses the `assistant` role, the response content will
            continue immediately from the content in that message. This can be used to
            constrain part of the model's response.

            Example with a single `user` message:

            ```json
            [{ "role": "user", "content": "Hello, Claude" }]
            ```

            Example with multiple conversational turns:

            ```json
            [
              { "role": "user", "content": "Hello there." },
              { "role": "assistant", "content": "Hi, I'm Claude. How can I help you?" },
              { "role": "user", "content": "Can you explain LLMs in plain English?" }
            ]
            ```

            Example with a partially-filled response from Claude:

            ```json
            [
              {
                "role": "user",
                "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"
              },
              { "role": "assistant", "content": "The best answer is (" }
            ]
            ```

            Each input message `content` may be either a single `string` or an array of
            content blocks, where each block has a specific `type`. Using a `string` for
            `content` is shorthand for an array of one content block of type `"text"`. The
            following input messages are equivalent:

            ```json
            { "role": "user", "content": "Hello, Claude" }
            ```

            ```json
            { "role": "user", "content": [{ "type": "text", "text": "Hello, Claude" }] }
            ```

            Starting with Claude 3 models, you can also send image content blocks:

            ```json
            {
              "role": "user",
              "content": [
                {
                  "type": "image",
                  "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",
                    "data": "/9j/4AAQSkZJRg..."
                  }
                },
                { "type": "text", "text": "What is in this image?" }
              ]
            }
            ```

            We currently support the `base64` source type for images, and the `image/jpeg`,
            `image/png`, `image/gif`, and `image/webp` media types.

            See [examples](https://docs.anthropic.com/en/api/messages-examples) for more
            input examples.

            Note that if you want to include a
            [system prompt](https://docs.anthropic.com/en/docs/system-prompts), you can use
            the top-level `system` parameter â€” there is no `"system"` role for input
            messages in the Messages API.
          minItems: 1
          items:
            $ref: '#/components/schemas/Message'
        max_tokens:
          type: integer
          description: |
            The maximum number of tokens to generate before stopping.

            Note that our models may stop _before_ reaching this maximum. This parameter
            only specifies the absolute maximum number of tokens to generate.

            Different models have different maximum values for this parameter. See
            [models](https://docs.anthropic.com/en/docs/models-overview) for details.
        metadata:
          $ref: '#/components/schemas/CreateMessageRequestMetadata'
        stop_sequences:
          type: array
          description: |
            Custom text sequences that will cause the model to stop generating.

            Our models will normally stop when they have naturally completed their turn,
            which will result in a response `stop_reason` of `"end_turn"`.

            If you want the model to stop generating when it encounters custom strings of
            text, you can use the `stop_sequences` parameter. If the model encounters one of
            the custom sequences, the response `stop_reason` value will be `"stop_sequence"`
            and the response `stop_sequence` value will contain the matched stop sequence.
          items:
            type: string
        system:
          type: string
          description: |
            System prompt.

            A system prompt is a way of providing context and instructions to Claude, such
            as specifying a particular goal or role. See our
            [guide to system prompts](https://docs.anthropic.com/en/docs/system-prompts).
        temperature:
          type: number
          description: |
            Amount of randomness injected into the response.

            Defaults to `1.0`. Ranges from `0.0` to `1.0`. Use `temperature` closer to `0.0`
            for analytical / multiple choice, and closer to `1.0` for creative and
            generative tasks.

            Note that even with `temperature` of `0.0`, the results will not be fully
            deterministic.
        top_k:
          type: integer
          description: |
            Only sample from the top K options for each subsequent token.

            Used to remove "long tail" low probability responses.
            [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).

            Recommended for advanced use cases only. You usually only need to use
            `temperature`.
        top_p:
          type: number
          description: |
            Use nucleus sampling.

            In nucleus sampling, we compute the cumulative distribution over all the options
            for each subsequent token in decreasing probability order and cut it off once it
            reaches a particular probability specified by `top_p`. You should either alter
            `temperature` or `top_p`, but not both.

            Recommended for advanced use cases only. You usually only need to use
            `temperature`.
        stream:
          type: boolean
          default: false
          description: |
            Whether to incrementally stream the response using server-sent events.

            See [streaming](https://docs.anthropic.com/en/api/messages-streaming) for
            details.
      required:
        - model
        - messages
        - max_tokens
    CreateMessageRequestMetadata:
      type: object
      description: An object describing metadata about the request.
      properties:
        user_id:
          type: string
          description: |
            An external identifier for the user who is associated with the request.

            This should be a uuid, hash value, or other opaque identifier. Anthropic may use
            this id to help detect abuse. Do not include any identifying information such as
            name, email address, or phone number.
    Message:
      type: object
      description: A message in a chat conversation.
      properties:
        id:
          type: string
          description: |
            Unique object identifier.

            The format and length of IDs may change over time.
        content:
          description: The content of the message.
          oneOf:
            - type: string
              description: A single text block.
            - type: array
              description: An array of content blocks.
              items:
                $ref: "#/components/schemas/Block"
        role:
          $ref: "#/components/schemas/MessageRole"
        model:
          type: string
          description: The model that handled the request.
        stop_reason:
          $ref: "#/components/schemas/StopReason"
        stop_sequence:
          type: string
          description: |
            Which custom stop sequence was generated, if any.

            This value will be a non-null string if one of your custom stop sequences was
            generated.
        type:
          type: string
          description: |
            Object type.

            For Messages, this is always `"message"`.
        usage:
          $ref: "#/components/schemas/Usage"
      required:
        - content
        - role
    MessageRole:
      type: string
      description: The role of the messages author.
      enum:
          - user
          - assistant
    Block:
      description: A block of content in a message.
      oneOf:
        - $ref: "#/components/schemas/TextBlock"
        - $ref: "#/components/schemas/ImageBlock"
      discriminator:
        propertyName: type
    TextBlock:
      type: object
      description: A block of text content.
      properties:
        text:
          type: string
          description: The text content.
        type:
          type: string
          description: The type of content block.
          default: text
      required:
        - text
    ImageBlock:
      type: object
      description: A block of image content.
      properties:
        source:
          $ref: "#/components/schemas/ImageBlockSource"
        type:
          type: string
          description: The type of content block.
          default: image
      required:
        - source
    ImageBlockSource:
      type: object
      description: The source of an image block.
      properties:
        data:
          type: string
          description: The base64-encoded image data.
        media_type:
          type: string
          description: The media type of the image.
          enum:
            - image/jpeg
            - image/png
            - image/gif
            - image/webp
        type:
          type: string
          description: The type of image source.
          enum:
            - base64
      required:
        - data
        - media_type
        - type
    StopReason:
      type: string
      description: |
        The reason that we stopped.
        
        This may be one the following values:
        
        - `"end_turn"`: the model reached a natural stopping point
        - `"max_tokens"`: we exceeded the requested `max_tokens` or the model's maximum
        - `"stop_sequence"`: one of your provided custom `stop_sequences` was generated
        
        In non-streaming mode this value is always non-null. In streaming mode, it is
        null in the `message_start` event and non-null otherwise.
      enum:
        - end_turn
        - max_tokens
        - stop_sequence
    Usage:
      type: object
      description: |
        Billing and rate-limit usage.
        
        Anthropic's API bills and rate-limits by token counts, as tokens represent the
        underlying cost to our systems.
        
        Under the hood, the API transforms requests into a format suitable for the
        model. The model's output then goes through a parsing stage before becoming an
        API response. As a result, the token counts in `usage` will not match one-to-one
        with the exact visible content of an API request or response.
        
        For example, `output_tokens` will be non-zero, even for an empty string response
        from Claude.
      properties:
        input_tokens:
          type: integer
          description: The number of input tokens which were used.
        output_tokens:
          type: integer
          description: The number of output tokens which were used.
      required:
        - input_tokens
        - output_tokens
    MessageStreamEvent:
      type: object
      description: A event in a streaming conversation.
      oneOf:
        - $ref: "#/components/schemas/MessageStartEvent"
        - $ref: "#/components/schemas/MessageDeltaEvent"
        - $ref: "#/components/schemas/MessageStopEvent"
        - $ref: "#/components/schemas/ContentBlockStartEvent"
        - $ref: "#/components/schemas/ContentBlockDeltaEvent"
        - $ref: "#/components/schemas/ContentBlockStopEvent"
        - $ref: "#/components/schemas/PingEvent"
      discriminator:
        propertyName: type
    MessageStreamEventType:
      type: string
      description: The type of a streaming event.
      enum:
        - message_start
        - message_delta
        - message_stop
        - content_block_start
        - content_block_delta
        - content_block_stop
        - ping
    MessageStartEvent:
      type: object
      description: A start event in a streaming conversation.
      properties:
        message:
          $ref: "#/components/schemas/Message"
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - message
        - type
    MessageDeltaEvent:
      type: object
      description: A delta event in a streaming conversation.
      properties:
        delta:
          $ref: "#/components/schemas/MessageDelta"
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
        usage:
          $ref: "#/components/schemas/MessageDeltaUsage"
      required:
        - delta
        - type
        - usage
    MessageDelta:
      type: object
      description: A delta in a streaming message.
      properties:
        stop_reason:
          $ref: "#/components/schemas/StopReason"
        stop_sequence:
          type: string
          description: |
            Which custom stop sequence was generated, if any.

            This value will be a non-null string if one of your custom stop sequences was
            generated.
    MessageDeltaUsage:
      type: object
      description: |
        Billing and rate-limit usage.
        
        Anthropic's API bills and rate-limits by token counts, as tokens represent the
        underlying cost to our systems.
        
        Under the hood, the API transforms requests into a format suitable for the
        model. The model's output then goes through a parsing stage before becoming an
        API response. As a result, the token counts in `usage` will not match one-to-one
        with the exact visible content of an API request or response.
        
        For example, `output_tokens` will be non-zero, even for an empty string response
        from Claude.
      properties:
        output_tokens:
          type: integer
          description: The cumulative number of output tokens which were used.
      required:
        - output_tokens
    MessageStopEvent:
      type: object
      description: A stop event in a streaming conversation.
      properties:
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - type
    ContentBlockStartEvent:
      type: object
      description: A start event in a streaming content block.
      properties:
        content_block:
          $ref: "#/components/schemas/TextBlock"
        index:
          type: integer
          description: The index of the content block.
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - content_block
        - index
        - type
    ContentBlockDeltaEvent:
      type: object
      description: A delta event in a streaming content block.
      properties:
        delta:
          $ref: "#/components/schemas/TextBlockDelta"
        index:
          type: integer
          description: The index of the content block.
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - delta
        - index
        - type
    TextBlockDelta:
      type: object
      description: A delta in a streaming text block.
      properties:
        text:
          type: string
          description: The text delta.
        type:
          type: string
          description: The type of content block.
          default: text_delta
      required:
        - text
        - type
    ContentBlockStopEvent:
      type: object
      description: A stop event in a streaming content block.
      properties:
        index:
          type: integer
          description: The index of the content block.
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - index
        - type
    PingEvent:
      type: object
      description: A ping event in a streaming conversation.
      properties:
        type:
          $ref: "#/components/schemas/MessageStreamEventType"
      required:
        - type

security:
  - ApiKeyAuth: [ ]
