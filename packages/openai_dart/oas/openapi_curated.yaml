#file: noinspection YAMLUnusedAnchor, YAMLSchemaValidation
openapi: 3.0.0

info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  version: "2.1.0"
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE

servers:
  - url: https://api.openai.com/v1

tags:
  - name: Assistants
    description: Build Assistants that can call models and use tools.
  - name: Chat
    description: Given a list of messages comprising a conversation, the model will return a response.
  - name: Completions
    description: Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.
  - name: Embeddings
    description: Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
  - name: Fine-tuning
    description: Manage fine-tuning jobs to tailor a model to your specific training data.
  - name: Batch
    description: Create large batches of API requests to run asynchronously.
  - name: Images
    description: Given a prompt and/or an input image, the model will generate a new image.
  - name: Models
    description: List and describe the various models available in the API.
  - name: Moderations
    description: Given a input text, outputs if the model classifies it as potentially harmful.

paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: Creates a model response for the given chat conversation.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
  /completions:
    post:
      operationId: createCompletion
      tags:
        - Completions
      summary: Creates a completion for the provided prompt and parameters.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateCompletionResponse"
  /embeddings:
    post:
      operationId: createEmbedding
      tags:
        - Embeddings
      summary: Creates an embedding vector representing the input text.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEmbeddingRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateEmbeddingResponse"
  /fine_tuning/jobs:
    post:
      operationId: createFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateFineTuningJobRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
    get:
      operationId: listPaginatedFineTuningJobs
      tags:
        - Fine-tuning
      summary: |
        List your organization's fine-tuning jobs.
      parameters:
        - name: after
          in: query
          description: Identifier for the last job from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of fine-tuning jobs to retrieve.
          required: false
          schema:
            type: integer
            default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListPaginatedFineTuningJobsResponse"
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: retrieveFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: listFineTuningEvents
      tags:
        - Fine-tuning
      summary: |
        Get status updates for a fine-tuning job.
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job to get events for.
        - name: after
          in: query
          description: Identifier for the last event from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of events to retrieve.
          required: false
          schema:
            type: integer
            default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningJobEventsResponse"
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: cancelFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Immediately cancel a fine-tune job.
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job to cancel.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
  /fine_tuning/jobs/{fine_tuning_job_id}/checkpoints:
    get:
      operationId: listFineTuningJobCheckpoints
      tags:
        - Fine-tuning
      summary: |
        List checkpoints for a fine-tuning job.
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job to get checkpoints for.
        - name: after
          in: query
          description: Identifier for the last checkpoint ID from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of checkpoints to retrieve.
          required: false
          schema:
            type: integer
            default: 10
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningJobCheckpointsResponse"
  /images/generations:
    post:
      operationId: createImage
      tags:
        - Images
      summary: Creates an image given a prompt.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateImageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
  /models:
    get:
      operationId: listModels
      tags:
        - Models
      summary: Lists the currently available models, and provides basic information about each one such as the owner and availability.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListModelsResponse"
  /models/{model}:
    get:
      operationId: retrieveModel
      tags:
        - Models
      summary: Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
      parameters:
        - in: path
          name: model
          required: true
          schema:
            type: string
            # ideally this will be an actual ID, so this will always work from browser
            example: gpt-3.5-turbo
          description: The ID of the model to use for this request
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Model"
    delete:
      operationId: deleteModel
      tags:
        - Models
      summary: Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
      parameters:
        - in: path
          name: model
          required: true
          schema:
            type: string
            example: ft:gpt-3.5-turbo:acemeco:suffix:abc123
          description: The model to delete
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteModelResponse"
  /moderations:
    post:
      operationId: createModeration
      tags:
        - Moderations
      summary: Classifies if text is potentially harmful.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateModerationRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateModerationResponse"
  /assistants:
    get:
      operationId: listAssistants
      tags:
        - Assistants
      summary: Returns a list of assistants.
      parameters:
        - name: limit
          in: query
          description: &pagination_limit_param_description |
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: &pagination_order_param_description |
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: &pagination_after_param_description |
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: &pagination_before_param_description |
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListAssistantsResponse"
    post:
      operationId: createAssistant
      tags:
        - Assistants
      summary: Create an assistant with a model and instructions.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateAssistantRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
  /assistants/{assistant_id}:
    get:
      operationId: getAssistant
      tags:
        - Assistants
      summary: Retrieves an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
    post:
      operationId: modifyAssistant
      tags:
        - Assistant
      summary: Modifies an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyAssistantRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
    delete:
      operationId: deleteAssistant
      tags:
        - Assistants
      summary: Delete an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteAssistantResponse"
  /threads:
    post:
      operationId: createThread
      tags:
        - Assistants
      summary: Create a thread.
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
  /threads/{thread_id}:
    get:
      operationId: getThread
      tags:
        - Assistants
      summary: Retrieves a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
    post:
      operationId: modifyThread
      tags:
        - Assistants
      summary: Modifies a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to modify. Only the `metadata` can be modified.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyThreadRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
    delete:
      operationId: deleteThread
      tags:
        - Assistants
      summary: Delete a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteThreadResponse"
  /threads/{thread_id}/messages:
    get:
      operationId: listThreadMessages
      tags:
        - Assistants
      summary: Returns a list of messages for a given thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) the messages belong to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
        - name: run_id
          in: query
          description: |
            Filter messages by the run ID that generated them.
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListMessagesResponse"
    post:
      operationId: createThreadMessage
      tags:
        - Assistants
      summary: Create a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to create a message for.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateMessageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
  /threads/{thread_id}/messages/{message_id}:
    get:
      operationId: getThreadMessage
      tags:
        - Assistants
      summary: Retrieve a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
    post:
      operationId: modifyThreadMessage
      tags:
        - Assistants
      summary: Modifies a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyMessageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
    delete:
      operationId: deleteThreadMessage
      tags:
        - Assistants
      summary: Deletes a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteMessageResponse"
  /threads/runs:
    post:
      operationId: createThreadAndRun
      tags:
        - Assistants
      summary: Create a thread and run it in one request.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadAndRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs:
    get:
      operationId: listThreadRuns
      tags:
        - Assistants
      summary: Returns a list of runs belonging to a thread.
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run belongs to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunsResponse"
    post:
      operationId: createThreadRun
      tags:
        - Assistants
      summary: Create a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to run.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getThreadRun
      tags:
        - Assistants
      summary: Retrieves a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
    post:
      operationId: modifyThreadRun
      tags:
        - Assistants
      summary: Modifies a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitThreadToolOutputsToRun
      tags:
        - Assistants
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this run belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run that requires the tool output submission.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SubmitToolOutputsRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelThreadRun
      tags:
        - Assistants
      summary: Cancels a run that is `in_progress`.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this run belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to cancel.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listThreadRunSteps
      tags:
        - Assistants
      summary: Returns a list of run steps belonging to a run.
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run and run steps belong to.
        - name: run_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the run the run steps belong to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunStepsResponse"
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getThreadRunStep
      tags:
        - Assistants
      summary: Retrieves a run step.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which the run and run step belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to which the run step belongs.
        - in: path
          name: step_id
          required: true
          schema:
            type: string
          description: The ID of the run step to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunStepObject"
  /vector_stores:
    get:
      operationId: listVectorStores
      tags:
        - Vector Stores
      summary: Returns a list of vector stores.
      parameters:
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoresResponse"
    post:
      operationId: createVectorStore
      tags:
        - Vector Stores
      summary: Create a vector store.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
  /vector_stores/{vector_store_id}:
    get:
      operationId: getVectorStore
      tags:
        - Vector Stores
      summary: Retrieves a vector store.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
    post:
      operationId: modifyVectorStore
      tags:
        - Vector Stores
      summary: Modifies a vector store.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UpdateVectorStoreRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreObject"
    delete:
      operationId: deleteVectorStore
      tags:
        - Vector Stores
      summary: Delete a vector store.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteVectorStoreResponse"
  /vector_stores/{vector_store_id}/files:
    get:
      operationId: listVectorStoreFiles
      tags:
        - Vector Stores
      summary: Returns a list of vector store files.
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
        - name: filter
          in: query
          description: "Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`."
          schema:
            type: string
            enum: [ "in_progress", "completed", "failed", "cancelled" ]
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoreFilesResponse"
    post:
      operationId: createVectorStoreFile
      tags:
        - Vector Stores
      summary: Create a vector store file by attaching a [File](https://platform.openai.com/docs/api-reference/files) to a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: |
            The ID of the vector store for which to create a File.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreFileRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileObject"
  /vector_stores/{vector_store_id}/files/{file_id}:
    get:
      summary: Retrieves a vector store file.
      operationId: getVectorStoreFile
      tags:
        - Vector Stores
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store that the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
            example: file-abc123
          description: The ID of the file being retrieved.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileObject"
    delete:
      summary: Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](https://platform.openai.com/docs/api-reference/files/delete) endpoint.
      operationId: deleteVectorStoreFile
      tags:
        - Vector Stores
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store that the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
          description: The ID of the file to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteVectorStoreFileResponse"
  /vector_stores/{vector_store_id}/file_batches:
    post:
      operationId: createVectorStoreFileBatch
      tags:
        - Vector Stores
      summary: Create a vector store file batch.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: |
            The ID of the vector store for which to create a File Batch.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVectorStoreFileBatchRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
  /vector_stores/{vector_store_id}/file_batches/{batch_id}:
    get:
      operationId: getVectorStoreFileBatch
      tags:
        - Vector Stores
      summary: Retrieves a vector store file batch.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store that the file batch belongs to.
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
            example: vsfb_abc123
          description: The ID of the file batch being retrieved.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel:
    post:
      operationId: cancelVectorStoreFileBatch
      tags:
        - Vector Stores
      summary: Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store that the file batch belongs to.
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
          description: The ID of the file batch to cancel.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VectorStoreFileBatchObject"
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/files:
    get:
      summary: Returns a list of vector store files in a batch.
      operationId: listFilesInVectorStoreBatch
      tags:
        - Vector Stores
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
        - name: filter
          in: query
          description: "Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`."
          schema:
            type: string
            enum: [ "in_progress", "completed", "failed", "cancelled" ]
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListVectorStoreFilesResponse"
  /batches:
    post:
      summary: Creates and executes a batch from an uploaded file of requests
      operationId: createBatch
      tags:
        - Batch
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateBatchRequest'
      responses:
        '200':
          description: Batch created successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
    get:
      summary: List your organization's batches.
      operationId: listBatches
      tags:
        - Batch
      parameters:
        - in: query
          name: after
          required: false
          schema:
            type: string
          description: *pagination_after_param_description
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
      responses:
        "200":
          description: Batch listed successfully.
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListBatchesResponse"
  /batches/{batch_id}:
    get:
      operationId: retrieveBatch
      tags:
        - Batch
      summary: Retrieves a batch.
      parameters:
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
          description: The ID of the batch to retrieve.
      responses:
        '200':
          description: Batch retrieved successfully.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
  /batches/{batch_id}/cancel:
    post:
      operationId: cancelBatch
      tags:
        - Batch
      summary: Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.
      parameters:
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
          description: The ID of the batch to cancel.
      responses:
        '200':
          description: Batch is cancelling. Returns the cancelling batch's details.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
components:

  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: 'bearer'

  schemas:
    CreateCompletionRequest:
      type: object
      description: Request object for the Create completion endpoint.
      properties:
        model:
          title: CompletionModel
          description: &model_description |
            ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: CompletionModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "gpt-3.5-turbo-instruct", "davinci-002", "babbage-002" ]
        prompt:
          title: CompletionPrompt
          description: &completions_prompt_description |
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
          default: "<|endoftext|>"
          nullable: true
          oneOf:
            - type: string
              description: A string prompt.
              default: ""
              example: "This is a test."
            - type: array
              description: A list of string prompts.
              items:
                type: string
                default: ""
                example: "This is a test."
            - type: array
              description: A tokenized prompt.
              minItems: 1
              items:
                type: integer
              example: "[1212, 318, 257, 1332, 13]"
            - type: array
              description: A list of tokenized prompts.
              minItems: 1
              items:
                type: array
                minItems: 1
                items:
                  type: integer
              example: "[[1212, 318, 257, 1332, 13]]"
        best_of:
          type: integer
          # default: 1 # Creates issues
          minimum: 0
          maximum: 20
          nullable: true
          description: &completions_best_of_description |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.
            
            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
        echo:
          type: boolean
          default: false
          nullable: true
          description: &completions_echo_description >
            Echo back the prompt in addition to the completion
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: &completions_frequency_penalty_description |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)
        logit_bias: &completions_logit_bias
          type: object
          default: null
          nullable: true
          additionalProperties:
            type: integer
          description: &completions_logit_bias_description |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](https://platform.openai.com/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
        logprobs: &completions_logprobs_configuration
          type: integer
          minimum: 0
          maximum: 5
          default: null
          nullable: true
          description: &completions_logprobs_description |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
        max_tokens:
          type: integer
          minimum: 0
          default: 16
          example: 16
          nullable: true
          description: &completions_max_tokens_description |
            The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
        n:
          type: integer
          minimum: 1
          maximum: 128
          default: 1
          example: 1
          nullable: true
          description: &completions_completions_description |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: &completions_presence_penalty_description |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)
        seed: &completions_seed_param
          type: integer
          # minimum: -9223372036854775808 # The value can't be represented exactly in JavaScript
          # maximum: 9223372036854775807
          nullable: true
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
        stop:
          title: CompletionStop
          description: &completions_stop_description >
            Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
          default: null
          nullable: true
          oneOf:
            - type: string
              description: A string stop sequence.
              default: <|endoftext|>
              example: "\n"
              nullable: true
            - type: array
              description: A list of string stop sequences.
              minItems: 1
              maxItems: 4
              items:
                type: string
                example: '["\n"]'
        stream:
          description: >
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
          default: false
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        suffix:
          description: |
            The suffix that comes after a completion of inserted text.
            
            This parameter is only supported for `gpt-3.5-turbo-instruct`.
          default: null
          nullable: true
          type: string
          example: "test."
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: &completions_temperature_description |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &completions_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
        user: &end_user_param_configuration
          type: string
          example: user-1234
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).
      required:
        - model
        - prompt
    CreateCompletionResponse:
      type: object
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      properties:
        id:
          type: string
          description: A unique identifier for the completion.
        choices:
          type: array
          description: The list of completion choices the model generated for the input prompt.
          items:
            $ref: "#/components/schemas/CompletionChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was created.
        model:
          type: string
          description: The model used for completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always "text_completion"
          enum: [ text_completion ]
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - id
        - object
        - created
        - model
        - choices
    CompletionChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - finish_reason
        - index
        - logprobs
        - text
      properties:
        finish_reason:
          $ref: "#/components/schemas/CompletionFinishReason"
        index:
          type: integer
          description: The index of the choice in the list of generated choices.
        logprobs:
          $ref: "#/components/schemas/CompletionLogprobs"
          nullable: true
        text:
          type: string
          description: The text of the completion.
    CompletionFinishReason:
      type: string
      nullable: true
      description: &completion_finish_reason_description |
        The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        `length` if the maximum number of tokens specified in the request was reached,
        or `content_filter` if content was omitted due to a flag from our content filters.
      enum: [ "stop", "length", "content_filter" ]
    CompletionLogprobs:
      type: object
      description: |
        The probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
      properties:
        text_offset:
          type: array
          description: The offset of the token from the beginning of the prompt.
          items:
            type: integer
        token_logprobs:
          type: array
          description: The log probabilities of tokens in the completion.
          items:
            type: number
            nullable: true
        tokens:
          type: array
          description: The tokens generated by the model converted back to text.
          items:
            type: string
        top_logprobs:
          type: array
          description: The log probabilities of the `logprobs` most likely tokens.
          items:
            type: object
            nullable: true
            additionalProperties:
              type: number
    CreateChatCompletionRequest:
      type: object
      description: Request object for the Create chat completion endpoint.
      properties:
        model:
          title: ChatCompletionModel
          description: ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.
          example: "gpt-4-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ChatCompletionModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "gpt-4",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-4-0125-preview",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-1106-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-2024-04-09",
                  "gpt-4-turbo-preview",
                  "gpt-4-vision-preview",
                  "gpt-4o",
                  "gpt-4o-2024-05-13",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-16k-0613",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                ]
        messages:
          description: A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
          type: array
          minItems: 1
          items:
            $ref: "#/components/schemas/ChatCompletionMessage"
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: *completions_frequency_penalty_description
        logit_bias:
          type: object
          default: null
          nullable: true
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        logprobs:
          description: Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.
          type: boolean
          nullable: true
        top_logprobs:
          description: An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.
          type: integer
          minimum: 0
          maximum: 20
          nullable: true
        max_tokens:
          description: |
            The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in the chat completion.

            The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          type: integer
          nullable: true
        n:
          type: integer
          minimum: 1
          maximum: 128
          default: 1
          example: 1
          nullable: true
          description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: *completions_presence_penalty_description
        response_format:
          title: ChatCompletionResponseFormat
          type: object
          description: |
            An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          properties:
            type:
              type: string
              enum: [ "text", "json_object" ]
              example: "json_object"
              default: "text"
              description: Must be one of `text` or `json_object`.
        seed:
          type: integer
          # minimum: -9223372036854775808 # The value can't be represented exactly in JavaScript
          # maximum: 9223372036854775807
          nullable: true
          description: |
            This feature is in Beta. 
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
        stop:
          title: ChatCompletionStop
          description: |
            Up to 4 sequences where the API will stop generating further tokens.
          default: null
          oneOf:
            - type: string
              description: A string stop sequence.
              nullable: true
            - type: array
              description: A list of string stop sequences.
              minItems: 1
              maxItems: 4
              items:
                type: string
        stream:
          description: >
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
          default: false
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: *completions_temperature_description
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: *completions_top_p_description
        tools:
          type: array
          description: >
            A list of tools the model may call. Currently, only functions are supported as a tool.
            Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
        tool_choice:
          title: ChatCompletionToolChoiceOption
          description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tool and instead generates a message.
            `auto` means the model can pick between generating a message or calling one or more tools.
            `required` means the model must call one or more tools.
            Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
            
            `none` is the default when no tools are present. `auto` is the default if tools are present.
          oneOf:
            - type: string
              title: ChatCompletionToolChoiceMode
              description: >
                `none` means the model will not call any tool and instead generates a message.
                `auto` means the model can pick between generating a message or calling one or more tools.
                `required` means the model must call one or more tools.
              enum: [ none, auto, required ]
            - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
        parallel_tool_calls: &parallel_tool_calls
          description: |
            Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) 
            during tool use.
          type: boolean
          default: true
          nullable: true
        user: *end_user_param_configuration
        function_call:
          title: ChatCompletionFunctionCall
          deprecated: true
          description: |
            Deprecated in favor of `tool_choice`.
            
            Controls which (if any) function is called by the model.
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
            Specifying a particular function via [ChatCompletionFunctionCallOption] forces the model to call that function.
            
            `none` is the default when no functions are present. `auto` is the default if functions are present.
          oneOf:
            - type: string
              title: ChatCompletionFunctionCallMode
              description: >
                `none` means the model will not call a function and instead generates a message.
                `auto` means the model can pick between generating a message or calling a function.
              enum: [ none, auto ]
            - $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
        functions:
          deprecated: true
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for.
          type: array
          minItems: 1
          maxItems: 128
          items:
            $ref: "#/components/schemas/FunctionObject"
      required:
        - model
        - messages
    ChatCompletionMessage:
      type: object
      description: A message in a chat conversation.
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionSystemMessage"
        - $ref: "#/components/schemas/ChatCompletionUserMessage"
        - $ref: "#/components/schemas/ChatCompletionAssistantMessage"
        - $ref: "#/components/schemas/ChatCompletionToolMessage"
        - $ref: "#/components/schemas/ChatCompletionFunctionMessage"
      discriminator:
        propertyName: role
    ChatCompletionSystemMessage:
      type: object
      description: A system message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: system
          description: The role of the messages author, in this case `system`.
        content:
          description: The contents of the system message.
          type: string
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
    ChatCompletionUserMessage:
      type: object
      description: A user message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: user
          description: The role of the messages author, in this case `user`.
        content:
          # TODO extract to ChatCompletionMessageContent once generator bug fixed
          description: The contents of the user message.
          oneOf:
            - type: string
              description: The text contents of the message.
            - type: array
              description: An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Image input is only supported when using the `gpt-4-vision-preview` model.
              items:
                $ref: "#/components/schemas/ChatCompletionMessageContentPart"
              minItems: 1
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
    ChatCompletionAssistantMessage:
      type: object
      description: An assistant message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: assistant
          description: The role of the messages author, in this case `assistant`.
        content:
          nullable: true
          type: string
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
          description: The tools that should be called, as generated by the model.
        function_call:
          $ref: "#/components/schemas/ChatCompletionMessageFunctionCall"
          deprecated: true
          description: "Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model."
    ChatCompletionToolMessage:
      type: object
      description: A tool message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: tool
          description: The role of the messages author, in this case `tool`.
        content:
          type: string
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      required:
        - content
        - tool_call_id
    ChatCompletionFunctionMessage:
      type: object
      description: A function message in a chat conversation.
      deprecated: true
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: function
          description: The role of the messages author, in this case `function`.
        content:
          type: string
          description: The contents of the function message.
          nullable: true
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
        - content
    ChatCompletionMessageContentPart:
      description: A content part of a user message.
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionMessageContentPartImage"
      discriminator:
        propertyName: type
    ChatCompletionMessageContentPartText:
      type: object
      description: A text content part of a user message.
      properties:
        type:
          $ref: "#/components/schemas/ChatCompletionMessageContentPartType"
          default: text
          description: The type of the content part, in this case `text`.
        text:
          type: string
          description: The text content.
      required:
        - text
    ChatCompletionMessageContentPartImage:
      type: object
      title: Image content part
      properties:
        type:
          $ref: "#/components/schemas/ChatCompletionMessageContentPartType"
          default: image_url
          description: The type of the content part, in this case `image_url`.
        image_url:
          title: ChatCompletionMessageImageUrl
          description: The URL of the image.
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              type: string
              title: ChatCompletionMessageImageDetail
              description: Specifies the detail level of the image. Learn more in the [Vision guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding).
              enum: [ "auto", "low", "high" ]
              default: "auto"
          required:
            - url
      required:
        - image_url
    ChatCompletionMessageContentPartType:
      type: string
      enum: [ "text", "image_url" ]
      description: The type of the content part.
    ChatCompletionMessageRole:
      type: string
      description: The role of the messages author. One of `system`, `user`, `assistant`, or `tool` (`function` is deprecated).
      enum: [ "system", "user", "assistant", "tool", "function" ]
    ChatCompletionMessageFunctionCall:
      type: object
      description: The name and arguments of a function that should be called, as generated by the model.
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
      required:
        - name
        - arguments
    ChatCompletionFunctionCallOption:
      type: object
      description: Forces the model to call the specified function.
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
    FunctionObject:
      type: object
      description: A function that the model may call.
      properties:
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
      required:
        - name
    FunctionParameters:
      type: object
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
      additionalProperties: true
    ChatCompletionTool:
      type: object
      description: A tool the model may use.
      properties:
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - type
        - function
    ChatCompletionNamedToolChoice:
      type: object
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
      properties:
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
      required:
        - type
        - function
    ChatCompletionMessageToolCalls:
      type: array
      description: The tool calls generated by the model, such as function calls.
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"
    ChatCompletionMessageToolCall:
      type: object
      description: A tool call generated by the model, such as a function call.
      properties:
        # TODO: index included when streaming
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionMessageFunctionCall"
      required:
        - id
        - type
        - function
    ChatCompletionStreamOptions:
      description: |
        Options for streaming response. Only set this when you set `stream: true`.
      type: object
      properties:
        include_usage:
          type: boolean
          description: |
            If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.
    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          items:
            $ref: "#/components/schemas/ChatCompletionResponseChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          # enum: [ chat.completion ] # Anyscale API sends `text_completion` instead
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - choices
        - created
        # - id # Made nullable to support OpenRouter API which doesn't return this field with some models
        - model
        - object
    ChatCompletionResponseChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - finish_reason
        # - index # Made nullable to support OpenRouter API which doesn't return this field
        - message
        - logprobs
      properties:
        finish_reason:
          $ref: "#/components/schemas/ChatCompletionFinishReason"
          nullable: true
        index:
          type: integer
          description: The index of the choice in the list of choices.
        message:
          $ref: "#/components/schemas/ChatCompletionAssistantMessage"
        logprobs:
          $ref: "#/components/schemas/ChatCompletionLogprobs"
    ChatCompletionFinishReason:
      type: string
      description: &chat_completion_finish_reason_description |
        The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        `length` if the maximum number of tokens specified in the request was reached,
        `content_filter` if content was omitted due to a flag from our content filters,
        `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
      enum:
        [
          "stop",
          "length",
          "tool_calls",
          "content_filter",
          "function_call",
        ]
    ChatCompletionLogprobs: &chat_completion_response_logprobs
      description: Log probability information for the choice.
      type: object
      nullable: true
      properties:
        content:
          description: A list of message content tokens with log probability information.
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob"
          nullable: true
      required:
        - content
    ChatCompletionTokenLogprob:
      type: object
      description: Log probability information for a token.
      properties:
        token: &chat_completion_response_logprobs_token
          description: The token.
          type: string
        logprob: &chat_completion_response_logprobs_token_logprob
          description: The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
          type: number
        bytes: &chat_completion_response_logprobs_bytes
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          type: array
          items:
            type: integer
          nullable: true
        top_logprobs:
          description: List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionTokenTopLogprob"
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
    ChatCompletionTokenTopLogprob:
      type: object
      description: Most likely tokens and their log probability, at this token position.
      properties:
        token: *chat_completion_response_logprobs_token
        logprob: *chat_completion_response_logprobs_token_logprob
        bytes: *chat_completion_response_logprobs_bytes
      required:
        - token
        - logprob
        - bytes
    CreateChatCompletionStreamResponse:
      type: object
      description: Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has the same ID.
        choices:
          type: array
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`.
          items:
            $ref: "#/components/schemas/ChatCompletionStreamResponseChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
        model:
          type: string
          description: The model to generate the completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact
        object:
          type: string
          description: The object type, which is always `chat.completion.chunk`.
          # enum: [ chat.completion.chunk ] # OpenRouter API sends `chat.completion` instead
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - choices
        # - created # Made nullable to support FastChat API which doesn't return this field with some models
        # - id # Made nullable to support OpenRouter API which doesn't return this field with some models
        # - model # Made nullable to support TogetherAI API which doesn't return this field with some models
        # - object # Made nullable to support FastChat API which doesn't return this field with some models
    ChatCompletionStreamResponseChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - delta
        - finish_reason
        # - index # Made nullable to support OpenRouter API which doesn't return this field
      properties:
        delta:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta"
        logprobs: *chat_completion_response_logprobs
        finish_reason:
          $ref: "#/components/schemas/ChatCompletionFinishReason"
          nullable: true
        index:
          type: integer
          description: The index of the choice in the list of choices.
    ChatCompletionStreamResponseDelta:
      type: object
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          type: string
          description: The contents of the chunk message.
          nullable: true
        function_call:
          $ref: "#/components/schemas/ChatCompletionStreamMessageFunctionCall"
        tool_calls:
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionStreamMessageToolCallChunk"
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
    ChatCompletionStreamMessageFunctionCall:
      type: object
      description: The name and arguments of a function that should be called, as generated by the model.
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
    ChatCompletionStreamMessageToolCallChunk:
      type: object
      description: The tool that should be called, as generated by the model.
      properties:
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionStreamMessageFunctionCall"
      required:
        - index
    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          type: integer
          nullable: true
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    CreateEmbeddingRequest:
      type: object
      description: Request object for the Create embedding endpoint.
      additionalProperties: false
      properties:
        model:
          title: EmbeddingModel
          description: *model_description
          example: "text-embedding-3-small"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: EmbeddingModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "text-embedding-ada-002",
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                ]
        input:
          title: EmbeddingInput
          description: |
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          example: "The quick brown fox jumped over the lazy dog"
          oneOf:
            - type: string
              description: A string prompt.
              default: ""
              example: "This is a test."
            - type: array
              description: A list of string prompts.
              minItems: 1
              maxItems: 2048
              items:
                type: string
                default: ""
                example: "This is a test."
            - type: array
              description: A tokenized prompt.
              minItems: 1
              maxItems: 2048
              items:
                type: integer
              example: "[1212, 318, 257, 1332, 13]"
            - type: array
              description: A list of tokenized prompts.
              minItems: 1
              maxItems: 2048
              items:
                type: array
                minItems: 1
                items:
                  type: integer
              example: "[[1212, 318, 257, 1332, 13]]"
        encoding_format:
          title: EmbeddingEncodingFormat
          description: "The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/)."
          example: "float"
          default: "float"
          type: string
          enum: [ "float", "base64" ]
        dimensions:
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
          type: integer
          minimum: 1
        user: *end_user_param_configuration
      required:
        - model
        - input
    CreateEmbeddingResponse:
      type: object
      description: Represents an embedding vector returned by embedding endpoint.
      properties:
        data:
          type: array
          description: The list of embeddings generated by the model.
          items:
            $ref: "#/components/schemas/Embedding"
        model:
          type: string
          description: The name of the model used to generate the embedding.
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
        usage:
          $ref: "#/components/schemas/EmbeddingUsage"
      required:
        - object
        - model
        - data
        # - usage # Made nullable to support Together AI API which doesn't return this field with some models
    Embedding:
      type: object
      description: |
        Represents an embedding vector returned by embedding endpoint.
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
        embedding:
          title: EmbeddingVector
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).
          oneOf:
            - type: string
              description: The embedding vector as a base64-encoded string.
            - type: array
              description: The embedding vector as a list of floats.
              items:
                type: number
        object:
          type: string
          description: The object type, which is always "embedding".
          enum: [ embedding ]
      required:
        - index
        - object
        - embedding
    EmbeddingUsage:
      type: object
      description: The usage information for the request.
      properties:
        prompt_tokens:
          type: integer
          description: The number of tokens used by the prompt.
        total_tokens:
          type: integer
          description: The total number of tokens used by the request.
      required:
        - prompt_tokens
        - total_tokens
    CreateFineTuningJobRequest:
      type: object
      description: Request object for the Create fine-tuning job endpoint.
      properties:
        model:
          title: FineTuningModel
          description: |
            The name of the model to fine-tune. You can select one of the
            [supported models](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
          example: "gpt-3.5-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: FineTuningModels
              description: |
                Available fine-tuning models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "babbage-002", "davinci-002", "gpt-3.5-turbo" ]
        training_file:
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose 
            `fine-tune`.

            The contents of the file should differ depending on if the model uses the 
            [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or 
            [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input) format.
            
            See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
          type: string
          example: "file-abc123"
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJobHyperparameters"
        suffix:
          description: |
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
          type: string
          minLength: 1
          maxLength: 40
          default: null
          nullable: true
        validation_file:
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
          type: string
          nullable: true
          example: "file-abc123"
        integrations:
          type: array
          description: A list of integrations to enable for your fine-tuning job.
          nullable: true
          items:
            $ref: "#/components/schemas/FineTuningIntegration"
        seed:
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you.
          type: integer
          nullable: true
          minimum: 0
          maximum: 2147483647
          example: 42
      required:
        - model
        - training_file
    FineTuningJob:
      type: object
      title: FineTuningJob
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        error:
          $ref: "#/components/schemas/FineTuningJobError"
        fine_tuned_model:
          type: string
          nullable: true
          description: The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.
        finished_at:
          type: integer
          nullable: true
          description: The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJobHyperparameters"
        model:
          type: string
          description: The base model that is being fine-tuned.
        object:
          type: string
          description: The object type, which is always "fine_tuning.job".
          enum: [ fine_tuning.job ]
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        result_files:
          type: array
          description: The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
          items:
            type: string
            example: file-abc123
        status:
          $ref: "#/components/schemas/FineTuningJobStatus"
        trained_tokens:
          type: integer
          nullable: true
          description: The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.
        training_file:
          type: string
          description: The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
        validation_file:
          type: string
          nullable: true
          description: The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
        integrations:
          type: array
          nullable: true
          description: A list of integrations to enable for this fine-tuning job.
          maxItems: 5
          items:
            $ref: "#/components/schemas/FineTuningIntegration"
          seed:
            type: integer
            description: The seed used for the fine-tuning job.
      required:
        - created_at
        - error
        - finished_at
        - fine_tuned_model
        - hyperparameters
        - id
        - model
        - object
        - organization_id
        - result_files
        - status
        - trained_tokens
        - training_file
        - validation_file
        - seed
    FineTuningIntegration:
      type: object
      description: A fine-tuning integration to enable for a fine-tuning job.
      required:
        - type
        - wandb
      properties:
        type:
          type: string
          description: |
            The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported.
          enum: [ "wandb" ]
        wandb:
          id: FineTuningIntegrationWandB
          type: object
          description: |
            The settings for your integration with Weights and Biases. This payload specifies the project that
            metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
            to your run, and set a default entity (team, username, etc) to be associated with your run.
          required:
            - project
          properties:
            project:
              description: |
                The name of the project that the new run will be created under.
              type: string
              example: "my-wandb-project"
            name:
              description: |
                A display name to set for the run. If not set, we will use the Job ID as the name.
              nullable: true
              type: string
            entity:
              description: |
                The entity to use for the run. This allows you to set the team or username of the WandB user that you would
                like associated with the run. If not set, the default entity for the registered WandB API key is used.
              nullable: true
              type: string
            tags:
              description: |
                A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
                default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
              type: array
              items:
                type: string
                example: "custom-tag"
    FineTuningJobStatus:
      type: string
      description: The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.
      enum:
        [
          "validating_files",
          "queued",
          "running",
          "succeeded",
          "failed",
          "cancelled",
        ]
    FineTuningJobError:
      type: object
      nullable: true
      description: For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.
      properties:
        code:
          type: string
          description: A machine-readable error code.
        message:
          type: string
          description: A human-readable error message.
        param:
          type: string
          description: The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.
          nullable: true
      required:
        - code
        - message
        - param
    FineTuningJobHyperparameters:
      type: object
      description: The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
      properties:
        n_epochs:
          title: FineTuningNEpochs
          description: |
            The number of epochs to train the model for. An epoch refers to one
            full cycle through the training dataset.
          oneOf:
            - type: string
              title: FineTuningNEpochsOptions
              description: The mode for the number of epochs.
              enum: [ auto ]
            - type: integer
              description: The number of epochs to train the model for.
              minimum: 1
              maximum: 50
          default: auto
      required:
        - n_epochs
    ListPaginatedFineTuningJobsResponse:
      type: object
      description: Represents a list of fine-tuning jobs.
      properties:
        data:
          type: array
          description: The list of fine-tuning jobs.
          items:
            $ref: "#/components/schemas/FineTuningJob"
        has_more:
          type: boolean
          description: Whether there are more fine-tuning jobs to retrieve.
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
      required:
        - object
        - data
        - has_more
    ListFineTuningJobEventsResponse:
      type: object
      description: Represents a list of fine-tuning job events.
      properties:
        data:
          type: array
          description: The list of fine-tuning job events.
          items:
            $ref: "#/components/schemas/FineTuningJobEvent"
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
      required:
        - object
        - data
    ListFineTuningJobCheckpointsResponse:
      type: object
      description: Represents a list of fine-tuning job checkpoints.
      properties:
        data:
          type: array
          description: The list of fine-tuning job checkpoints.
          items:
            $ref: "#/components/schemas/FineTuningJobCheckpoint"
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
        first_id:
          type: string
          description: The ID of the first checkpoint in the list.
          nullable: true
        last_id:
          type: string
          description: The ID of the last checkpoint in the list.
          nullable: true
        has_more:
          description: Whether there are more checkpoints to retrieve.
          type: boolean
      required:
        - object
        - data
        - has_more
    FineTuningJobEvent:
      type: object
      description: Fine-tuning job event object.
      properties:
        id:
          type: string
          description: The event identifier, which can be referenced in the API endpoints.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the event was created.
        level:
          type: string
          description: The log level of the event.
          enum: [ "info", "warn", "error" ]
        message:
          type: string
          description: The message of the event.
        object:
          type: string
          description: The object type, which is always "fine_tuning.job.event".
          enum: [ fine_tuning.job.event ]
      required:
        - id
        - object
        - created_at
        - level
        - message
    FineTuningJobCheckpoint:
      id: FineTuningJobCheckpoint
      type: object
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
      properties:
        id:
          type: string
          description: The checkpoint identifier, which can be referenced in the API endpoints.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the checkpoint was created.
        fine_tuned_model_checkpoint:
          type: string
          description: The name of the fine-tuned checkpoint model that is created.
        step_number:
          type: integer
          description: The step number that the checkpoint was created at.
        metrics:
          id: FineTuningJobCheckpointMetrics
          type: object
          description: Metrics at the step number during the fine-tuning job.
          properties:
            step:
              type: number
              description: The step number that the metrics were recorded at.
            train_loss:
              type: number
              description: The training loss at the step number.
            train_mean_token_accuracy:
              type: number
              description: The training mean token accuracy at the step number.
            valid_loss:
              type: number
              description: The validation loss at the step number.
            valid_mean_token_accuracy:
              type: number
              description: The validation mean token accuracy at the step number.
            full_valid_loss:
              type: number
              description: The full validation loss at the step number.
            full_valid_mean_token_accuracy:
              type: number
              description: The full validation mean token accuracy at the step number.
        fine_tuning_job_id:
          type: string
          description: The name of the fine-tuning job that this checkpoint was created from.
        object:
          type: string
          description: The object type, which is always "fine_tuning.job.checkpoint".
          enum: [ fine_tuning.job.checkpoint ]
      required:
        - created_at
        - fine_tuning_job_id
        - fine_tuned_model_checkpoint
        - id
        - metrics
        - object
        - step_number
    CreateImageRequest:
      type: object
      description: Request object for the Create image endpoint.
      properties:
        prompt:
          description: A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
          type: string
          example: "A cute baby sea otter"
        model:
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ImageModels
              description: |
                Available models for image generation. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "dall-e-2", "dall-e-3" ]
          default: "dall-e-2"
          example: "dall-e-3"
          nullable: true
          description: The model to use for image generation.
        n: &images_n
          type: integer
          minimum: 1
          maximum: 10
          default: 1
          example: 1
          nullable: true
          description: The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.
        quality:
          title: ImageQuality
          type: string
          enum: [ "standard", "hd" ]
          default: "standard"
          example: "standard"
          description: The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.
        response_format: &images_response_format
          title: ImageResponseFormat
          type: string
          enum: [ "url", "b64_json" ]
          default: "url"
          example: "url"
          nullable: true
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.
        size: &images_size
          title: ImageSize
          type: string
          enum: [ "256x256", "512x512", "1024x1024", "1792x1024", "1024x1792" ]
          default: "1024x1024"
          example: "1024x1024"
          nullable: true
          description: The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.
        style:
          title: ImageStyle
          type: string
          enum: [ "vivid", "natural" ]
          default: "vivid"
          example: "vivid"
          nullable: true
          description: The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.
        user: *end_user_param_configuration
      required:
        - prompt
    ImagesResponse:
      type: object
      description: Represents a generated image returned by the images endpoint.
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the image was created.
        data:
          type: array
          description: The list of images generated by the model.
          items:
            $ref: "#/components/schemas/Image"
      required:
        - created
        - data
    Image:
      type: object
      description: Represents the url or the content of an image generated by the OpenAI API.
      properties:
        b64_json:
          type: string
          description: The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
        url:
          type: string
          description: The URL of the generated image, if `response_format` is `url` (default).
        revised_prompt:
          type: string
          description: The prompt that was used to generate the image, if there was any revision to the prompt.
    Model:
      title: Model
      description: Describes an OpenAI model offering that can be used with the API.
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: The object type, which is always "model".
          enum: [ model ]
        owned_by:
          type: string
          description: The organization that owns the model.
      required:
        - id
        - object
        - created
        - owned_by
    ListModelsResponse:
      type: object
      description: Represents a list of models returned by the List models endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
        data:
          type: array
          description: The list of models.
          items:
            $ref: "#/components/schemas/Model"
      required:
        - object
        - data
    DeleteModelResponse:
      type: object
      description: Represents a deleted response returned by the Delete model endpoint.
      properties:
        id:
          type: string
          description: The model identifier.
        deleted:
          type: boolean
          description: Whether the model was deleted.
        object:
          type: string
          description: The object type, which is always "model".
      required:
        - id
        - object
        - deleted
    CreateModerationRequest:
      type: object
      description: Request object for the Create moderation endpoint.
      properties:
        model:
          title: ModerationModel
          description: |
            Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.

            The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
          default: "text-moderation-latest"
          example: "text-moderation-stable"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ModerationModels
              description: |
                Available moderation models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "text-moderation-latest", "text-moderation-stable" ]
        input:
          title: ModerationInput
          description: The input text to classify
          oneOf:
            - type: string
              description: A string input.
              default: ""
              example: "I want to kill them."
            - type: array
              description: A list of string inputs.
              items:
                type: string
                default: ""
                example: "I want to kill them."
      required:
        - input
    CreateModerationResponse:
      type: object
      description: Represents if a given text input is potentially harmful.
      properties:
        id:
          type: string
          description: The unique identifier for the moderation request.
        model:
          type: string
          description: The model used to generate the moderation results.
        results:
          type: array
          description: A list of moderation objects.
          items:
            $ref: "#/components/schemas/Moderation"
      required:
        - id
        - model
        - results
    Moderation:
      type: object
      description: Represents policy compliance report by OpenAI's content moderation model against a given input.
      properties:
        flagged:
          type: boolean
          description: Whether any of the below categories are flagged.
        categories:
          $ref: "#/components/schemas/ModerationCategories"
        category_scores:
          $ref: "#/components/schemas/ModerationCategoriesScores"
      required:
        - flagged
        - categories
        - category_scores
    ModerationCategories:
      type: object
      description: A list of the categories, and whether they are flagged or not.
      properties:
        hate:
          type: boolean
          description: Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.
        hate/threatening:
          type: boolean
          description: Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.
        harassment:
          type: boolean
          description: Content that expresses, incites, or promotes harassing language towards any target.
        harassment/threatening:
          type: boolean
          description: Harassment content that also includes violence or serious harm towards any target.
        self-harm:
          type: boolean
          description: Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.
        self-harm/intent:
          type: boolean
          description: Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.
        self-harm/instructions:
          type: boolean
          description: Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.
        sexual:
          type: boolean
          description: Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).
        sexual/minors:
          type: boolean
          description: Sexual content that includes an individual who is under 18 years old.
        violence:
          type: boolean
          description: Content that depicts death, violence, or physical injury.
        violence/graphic:
          type: boolean
          description: Content that depicts death, violence, or physical injury in graphic detail.
      required:
        - hate
        - hate/threatening
        - harassment
        - harassment/threatening
        - self-harm
        - self-harm/intent
        - self-harm/instructions
        - sexual
        - sexual/minors
        - violence
        - violence/graphic
    ModerationCategoriesScores:
      type: object
      description: A list of the categories along with their scores as predicted by model.
      properties:
        hate:
          type: number
          description: The score for the category 'hate'.
        hate/threatening:
          type: number
          description: The score for the category 'hate/threatening'.
        harassment:
          type: number
          description: The score for the category 'harassment'.
        harassment/threatening:
          type: number
          description: The score for the category 'harassment/threatening'.
        self-harm:
          type: number
          description: The score for the category 'self-harm'.
        self-harm/intent:
          type: number
          description: The score for the category 'self-harm/intent'.
        self-harm/instructions:
          type: number
          description: The score for the category 'self-harm/instructions'.
        sexual:
          type: number
          description: The score for the category 'sexual'.
        sexual/minors:
          type: number
          description: The score for the category 'sexual/minors'.
        violence:
          type: number
          description: The score for the category 'violence'.
        violence/graphic:
          type: number
          description: The score for the category 'violence/graphic'.
      required:
        - hate
        - hate/threatening
        - harassment
        - harassment/threatening
        - self-harm
        - self-harm/intent
        - self-harm/instructions
        - sexual
        - sexual/minors
        - violence
        - violence/graphic
    AssistantObject:
      type: object
      description: Represents an `assistant` that can call the model and use tools.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `assistant`.
          type: string
          enum: [ assistant ]
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was created.
          type: integer
        name:
          description: &assistant_name_param_description |
            The name of the assistant. The maximum length is 256 characters.
          type: string
          maxLength: 256
          nullable: true
        description:
          description: &assistant_description_param_description |
            The description of the assistant. The maximum length is 512 characters.
          type: string
          maxLength: 512
          nullable: true
        model:
          description: *model_description
          type: string
        instructions:
          description: &assistant_instructions_param_description |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          type: string
          maxLength: 256000
          nullable: true
        tools:
          description: &assistant_tools_param_description |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: &metadata_description |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          type: object
          additionalProperties: true
          nullable: true
        temperature:
          description: &run_temperature_description |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &run_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: AssistantResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
      required:
        - id
        - object
        - created_at
        - name
        - description
        - model
        - instructions
        - tools
        - metadata
    CreateAssistantRequest:
      type: object
      description: Request object for the Create assistant endpoint.
      additionalProperties: false
      properties:
        model:
          title: AssistantModel
          description: *model_description
          example: "gpt-4-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use.
            - type: string
              title: AssistantModels
              description: |
                Available assistant models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "gpt-4",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-4-0125-preview",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-1106-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-2024-04-09",
                  "gpt-4-turbo-preview",
                  "gpt-4-vision-preview",
                  "gpt-4o",
                  "gpt-4o-2024-05-13",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-16k-0613",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                ]
        name:
          description: *assistant_name_param_description
          type: string
          nullable: true
          maxLength: 256
        description:
          description: *assistant_description_param_description
          type: string
          nullable: true
          maxLength: 512
        instructions:
          description: *assistant_instructions_param_description
          type: string
          nullable: true
          maxLength: 256000
        tools:
          description: *assistant_tools_param_description
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        temperature:
          description: &run_temperature_description |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &run_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: CreateAssistantResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
      required:
        - model
    ModifyAssistantRequest:
      type: object
      description: Request object for the Modify assistant endpoint.
      additionalProperties: false
      properties:
        model:
          type: string
          description: *model_description
        name:
          description: *assistant_name_param_description
          type: string
          nullable: true
          maxLength: 256
        description:
          description: *assistant_description_param_description
          type: string
          nullable: true
          maxLength: 512
        instructions:
          description: *assistant_instructions_param_description
          type: string
          nullable: true
          maxLength: 256000
        tools:
          description: *assistant_tools_param_description
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        file_ids:
          description: |
            A list of [File](https://platform.openai.com/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previosuly attached to the list but does not show up in the list, it will be deleted from the assistant.
          default: [ ]
          type: array
          maxItems: 20
          items:
            type: string
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        temperature:
          description: *run_temperature_description
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &run_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: ModifyAssistantResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
    DeleteAssistantResponse:
      type: object
      description: Represents a deleted response returned by the Delete assistant endpoint.
      properties:
        id:
          type: string
          description: The assistant identifier.
        deleted:
          type: boolean
          description: Whether the assistant was deleted.
        object:
          type: string
          description: The object type, which is always `assistant.deleted`.
          enum: [ assistant.deleted ]
      required:
        - id
        - object
        - deleted
    ListAssistantsResponse:
      type: object
      description: Represents a list of assistants returned by the List assistants endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of assistants.
          items:
            $ref: "#/components/schemas/AssistantObject"
        first_id:
          type: string
          description: The ID of the first assistant in the list.
          example: "asst_abc123"
        last_id:
          type: string
          description: The ID of the last assistant in the list.
          example: "asst_abc456"
        has_more:
          type: boolean
          description: Whether there are more assistants to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    AssistantTools:
      type: object
      description: A tool that can be used by an assistant.
      oneOf:
        - $ref: "#/components/schemas/AssistantToolsCodeInterpreter"
        - $ref: "#/components/schemas/AssistantToolsFileSearch"
        - $ref: "#/components/schemas/AssistantToolsFunction"
      discriminator:
        propertyName: type
    AssistantToolsCodeInterpreter:
      type: object
      description: Code interpreter tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `code_interpreter`"
          default: "code_interpreter"
    AssistantToolsFileSearch:
      type: object
      description: FileSearch tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `file_search`"
          default: file_search
        file_search:
          type: object
          description: Overrides for the file search tool.
          properties:
            max_num_results:
              type: integer
              minimum: 1
              maximum: 50
              description: |
                The maximum number of results the file search tool should output. The default is 20 for gpt-4* models 
                and 5 for gpt-3.5-turbo. This number should be between 1 and 50 inclusive.
                
                Note that the file search tool may output fewer than `max_num_results` results. See the [file search 
                tool documentation](/docs/assistants/tools/file-search/number-of-chunks-returned) for more information.
      required:
        - type
    AssistantToolsFunction:
      type: object
      description: Function tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `function`"
          default: "function"
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - function
    AssistantsNamedToolChoice:
      type: object
      description: Specifies a tool the model should use. Use to force the model to call a specific tool.
      properties:
        type:
          type: string
          title: AssistantsToolType
          enum: [ "function", "code_interpreter", "file_search" ]
          description: The type of the tool. If type is `function`, the function name must be set
        function:
          $ref: "#/components/schemas/AssistantsFunctionCallOption"
      required:
        - type
    AssistantsFunctionCallOption:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
    AssistantsResponseFormat:
      type: object
      description: |
        An object describing the expected output of the model. If `json_object` only `function` type `tools` are allowed to be passed to the Run. If `text` the model can return text or any value needed.
      properties:
        type:
          type: string
          title: AssistantsResponseFormatType
          enum: [ "text", "json_object" ]
          example: "json_object"
          default: "text"
          description: Must be one of `text` or `json_object`.
    TruncationObject:
      type: object
      description: Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.
      properties:
        type:
          type: string
          name: TruncationStrategy
          description: The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
          enum: [ "auto", "last_messages" ]
        last_messages:
          type: integer
          description: The number of most recent messages from the thread when constructing the context for the run.
          minimum: 1
          nullable: true
      required:
        - type
    RunObject:
      type: object
      description: Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run`.
          type: string
          enum: [ "thread.run" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        thread_id:
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.
          type: string
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.
          type: string
        status:
          title: RunStatus
          description: The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.
          type: string
          enum:
            [
              "queued",
              "in_progress",
              "requires_action",
              "cancelling",
              "cancelled",
              "failed",
              "completed",
              "incomplete",
              "expired",
            ]
        required_action:
          title: RunRequiredAction
          type: object
          description: Details on the action required to continue the run. Will be `null` if no action is required.
          nullable: true
          properties:
            type:
              description: For now, this is always `submit_tool_outputs`.
              type: string
              enum: [ "submit_tool_outputs" ]
            submit_tool_outputs:
              title: RunSubmitToolOutputs
              type: object
              description: Details on the tool outputs needed for this run to continue.
              properties:
                tool_calls:
                  type: array
                  description: A list of the relevant tool calls.
                  items:
                    $ref: "#/components/schemas/RunToolCallObject"
              required:
                - tool_calls
          required:
            - type
            - submit_tool_outputs
        last_error:
          title: RunLastError
          type: object
          description: The last error associated with this run. Will be `null` if there are no errors.
          nullable: true
          properties:
            code:
              type: string
              description: One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.
              enum: [ "server_error", "rate_limit_exceeded", "invalid_prompt" ]
            message:
              type: string
              description: A human-readable description of the error.
          required:
            - code
            - message
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          type: integer
          nullable: true
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          type: integer
          nullable: true
        incomplete_details:
          description: Details on why the run is incomplete. Will be `null` if the run is not incomplete.
          type: object
          nullable: true
          properties:
            reason:
              description: The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.
              type: string
              enum: [ "max_completion_tokens", "max_prompt_tokens" ]
        model:
          description: The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          type: string
        instructions:
          description: The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          type: string
        tools:
          description: The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          default: [ ]
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        usage:
          $ref: "#/components/schemas/RunCompletionUsage"
        temperature:
          description: The sampling temperature used for this run. If not set, defaults to 1.
          type: number
          nullable: true
        top_p:
          description: The nucleus sampling value used for this run. If not set, defaults to 1.
          type: number
          nullable: true
        max_prompt_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run.
          minimum: 256
        max_completion_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run.
          minimum: 256
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tools and instead generates a message.
            `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
            `required` means the model must call one or more tools before responding to the user.
            Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
          nullable: true
          oneOf:
            - type: string
              title: RunObjectToolChoiceMode
              description: >
                `none` means the model will not call any tools and instead generates a message.
                `auto` means the model can pick between generating a message or calling one or more tools.
                `required` means the model must call one or more tools before responding to the user.
              enum: [ none, auto, required ]
            - $ref: "#/components/schemas/AssistantsNamedToolChoice"
        parallel_tool_calls: *parallel_tool_calls
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: RunObjectResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
      required:
        - id
        - object
        - created_at
        - thread_id
        - assistant_id
        - status
        - required_action
        - last_error
        - expires_at
        - started_at
        - cancelled_at
        - failed_at
        - completed_at
        - model
        - instructions
        - tools
        - metadata
        - usage
        - incomplete_details
        - max_prompt_tokens
        - max_completion_tokens
        - truncation_strategy
        - tool_choice
        - parallel_tool_calls
        - response_format
    RunCompletionUsage:
      type: object
      description: Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      nullable: true
    CreateRunRequest:
      type: object
      description: Request object for the Create run endpoint.
      additionalProperties: false
      properties:
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
          type: string
        model:
          id: RunModel
          description: The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
          example: "gpt-4-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: RunModels
              description: |
                Available models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "gpt-4",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-4-0125-preview",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-1106-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-2024-04-09",
                  "gpt-4-turbo-preview",
                  "gpt-4-vision-preview",
                  "gpt-4o",
                  "gpt-4o-2024-05-13",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-16k-0613",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                ]
        instructions:
          description: Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.
          type: string
          nullable: true
        additional_instructions:
          description: Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
          type: string
          nullable: true
        additional_messages:
          description: Adds additional messages to the thread before creating the run.
          type: array
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: *run_temperature_description
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &run_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
        max_prompt_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
        max_completion_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tools and instead generates a message.
            `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
            `required` means the model must call one or more tools before responding to the user.
            Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
          nullable: true
          oneOf:
            - type: string
              title: CreateRunRequestToolChoiceMode
              description: >
                `none` means the model will not call any tools and instead generates a message.
                `auto` means the model can pick between generating a message or calling one or more tools.
                `required` means the model must call one or more tools before responding to the user.
              enum: [ none, auto, required ]
            - $ref: "#/components/schemas/AssistantsNamedToolChoice"
        parallel_tool_calls: *parallel_tool_calls
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: CreateRunRequestResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
        stream:
          type: boolean
          nullable: true
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
      required:
        - assistant_id
    ListRunsResponse:
      type: object
      description: Represents a list of runs returned by the List runs endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of runs.
          items:
            $ref: "#/components/schemas/RunObject"
        first_id:
          type: string
          description: The ID of the first run in the list.
          example: "run_abc123"
        last_id:
          type: string
          description: The ID of the last run in the list.
          example: "run_abc456"
        has_more:
          type: boolean
          description: Whether there are more runs to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    ModifyRunRequest:
      type: object
      description: Request object for the Modify run endpoint.
      additionalProperties: false
      properties:
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    SubmitToolOutputsRunRequest:
      type: object
      description: Request object for the Submit tool outputs to run endpoint.
      additionalProperties: false
      properties:
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          type: array
          items:
            $ref: "#/components/schemas/RunSubmitToolOutput"
        stream:
          type: boolean
          nullable: true
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
      required:
        - tool_outputs
    RunSubmitToolOutput:
      type: object
      description: Output of a tool.
      properties:
        tool_call_id:
          type: string
          description: The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
        output:
          type: string
          description: The output of the tool call to be submitted to continue the run.
    RunToolCallObject:
      type: object
      description: Tool call objects
      properties:
        id:
          type: string
          description: The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.
        type:
          type: string
          description: The type of tool call the output is required for. For now, this is always `function`.
          enum: [ "function" ]
        function:
          type: object
          title: RunToolCallFunction
          description: The function definition.
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments that the model expects you to pass to the function.
          required:
            - name
            - arguments
      required:
        - id
        - type
        - function
    CreateThreadAndRunRequest:
      type: object
      description: Request object for the Create thread and run endpoint.
      additionalProperties: false
      properties:
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
          type: string
        thread:
          $ref: "#/components/schemas/CreateThreadRequest"
          description: If no thread is provided, an empty thread will be created.
        model:
          title: ThreadAndRunModel
          description: The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
          example: "gpt-4-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ThreadAndRunModels
              description: |
                Available models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "gpt-4",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-4-0125-preview",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-1106-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-2024-04-09",
                  "gpt-4-turbo-preview",
                  "gpt-4-vision-preview",
                  "gpt-4o",
                  "gpt-4o-2024-05-13",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-16k-0613",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                ]
        instructions:
          description: Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
          type: string
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: *run_temperature_description
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: *run_top_p_description
        max_prompt_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
        max_completion_tokens:
          type: integer
          nullable: true
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
          nullable: true
        tool_choice:
          description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tools and instead generates a message.
            `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
            `required` means the model must call one or more tools before responding to the user.
            Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
          nullable: true
          oneOf:
            - type: string
              title: CreateThreadAndRunRequestToolChoiceMode
              description: >
                `none` means the model will not call any tools and instead generates a message.
                `auto` means the model can pick between generating a message or calling one or more tools.
                `required` means the model must call one or more tools before responding to the user.
              enum: [ none, auto, required ]
            - $ref: "#/components/schemas/AssistantsNamedToolChoice"
        parallel_tool_calls: *parallel_tool_calls
        response_format:
          description: |
            Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models/gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
            
            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
            
            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          oneOf:
            - type: string
              title: CreateThreadAndRunRequestResponseFormatMode
              description: >
                `auto` is the default value
              enum: [ none, auto ]
            - $ref: "#/components/schemas/AssistantsResponseFormat"
        stream:
          type: boolean
          nullable: true
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
      required:
        - assistant_id
    ThreadObject:
      type: object
      description: Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread`.
          type: string
          enum: [ "thread" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - id
        - object
        - created_at
        - tool_resources
        - metadata
    CreateThreadRequest:
      type: object
      description: Request object for the Create thread endpoint.
      additionalProperties: false
      properties:
        messages:
          description: A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.
          type: array
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    ModifyThreadRequest:
      type: object
      description: Request object for the Modify thread endpoint.
      additionalProperties: false
      properties:
        tool_resources:
          $ref: "#/components/schemas/ToolResources"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    ToolResources:
      type: object
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          id: ToolResourcesCodeInterpreter
          type: object
          properties:
            file_ids:
              type: array
              description: |
                A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
              default: [ ]
              maxItems: 20
              items:
                type: string
        file_search:
          id: ToolResourcesFileSearch
          type: object
          properties:
            vector_store_ids:
              type: array
              description: |
                The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
              maxItems: 1
              items:
                type: string
            vector_stores:
              type: array
              description: |
                A helper to create a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
              maxItems: 1
              items:
                $ref: "#/components/schemas/ToolResourcesFileSearchVectorStore"
    ToolResourcesFileSearchVectorStore:
      type: object
      description: |
        A helper to create a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread.
      properties:
        file_ids:
          type: array
          description: |
            A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
          maxItems: 10000
          items:
            type: string
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
    DeleteThreadResponse:
      type: object
      properties:
        id:
          type: string
          description: The thread identifier.
        deleted:
          type: boolean
          description: Whether the thread was deleted.
        object:
          type: string
          description: The object type, which is always `thread.deleted`.
          enum: [ thread.deleted ]
      required:
        - id
        - object
        - deleted
    ListThreadsResponse:
      type: object
      description: Represents a list of threads returned by the List threads endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of threads.
          items:
            $ref: "#/components/schemas/ThreadObject"
        first_id:
          type: string
          description: The ID of the first thread in the list.
          example: "asst_hLBK7PXBv5Lr2NQT7KLY0ag1"
        last_id:
          type: string
          description: The ID of the last thread in the list.
          example: "asst_QLoItBbqwyAJEzlTy4y9kOMM"
        has_more:
          type: boolean
          description: Whether there are more threads to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    MessageObject:
      type: object
      description: Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.message`.
          type: string
          enum: [ "thread.message" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        thread_id:
          description: The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.
          type: string
        status:
          name: MessageStatus
          description: The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.
          type: string
          nullable: true
          enum: [ "in_progress", "incomplete", "completed" ]
        incomplete_details:
          id: MessageIncompleteDetails
          type: object
          description: On an incomplete message, details about why the message is incomplete.
          properties:
            reason:
              name: MessageIncompleteReason
              type: string
              description: The reason the message is incomplete.
              enum:
                [
                  "content_filter",
                  "max_tokens",
                  "run_cancelled",
                  "run_expired",
                  "run_failed",
                ]
          nullable: true
          required:
            - reason
        completed_at:
          description: The Unix timestamp (in seconds) for when the message was completed.
          type: integer
          nullable: true
        incomplete_at:
          description: The Unix timestamp (in seconds) for when the message was marked as incomplete.
          type: integer
          nullable: true
        role:
          $ref: "#/components/schemas/MessageRole"
        content:
          description: The content of the message in array of text and/or images.
          type: array
          items:
            $ref: "#/components/schemas/MessageContent"
        assistant_id:
          description: If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.
          type: string
          nullable: true
        run_id:
          description: The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.
          type: string
          nullable: true
        attachments:
          description: A list of files attached to the message, and the tools they were added to.
          type: array
          nullable: true
          items:
            $ref: "#/components/schemas/MessageAttachment"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - id
        - object
        - created_at
        - thread_id
        - status
        - incomplete_details
        - completed_at
        - incomplete_at
        - role
        - content
        - assistant_id
        - run_id
        - attachments
        - metadata
    MessageRole:
      type: string
      description: The entity that produced the message. One of `user` or `assistant`.
      enum: [ "user", "assistant" ]
    MessageAttachment:
      description: An attachment to a message.
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file to attach to the message.
        tools:
          description: The tools to add this file to.
          type: array
          items:
            $ref: "#/components/schemas/AssistantTools"
    MessageDeltaObject:
      type: object
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming.
      properties:
        id:
          description: The identifier of the message, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.message.delta`.
          type: string
          enum: [ "thread.message.delta" ]
        delta:
          $ref: "#/components/schemas/MessageDelta"
      required:
        - id
        - object
        - delta
    MessageDelta:
      type: object
      description: The delta containing the fields that have changed on the Message.
      properties:
        role:
          $ref: "#/components/schemas/MessageRole"
        content:
          description: The content of the message in array of text and/or images.
          type: array
          items:
            $ref: "#/components/schemas/MessageDeltaContent"
    MessageContent:
      type: object
      description: The content of a message.
      oneOf:
        - $ref: "#/components/schemas/MessageContentImageFileObject"
        - $ref: "#/components/schemas/MessageContentImageUrlObject"
        - $ref: "#/components/schemas/MessageContentTextObject"
      discriminator:
        propertyName: type
    MessageDeltaContent:
      type: object
      description: The content of a message delta.
      oneOf:
        - $ref: "#/components/schemas/MessageDeltaContentImageFileObject"
        - $ref: "#/components/schemas/MessageDeltaContentTextObject"
      discriminator:
        propertyName: type
    CreateMessageRequest:
      type: object
      description: Request object for the Create message endpoint.
      additionalProperties: false
      required:
        - role
        - content
      properties:
        role:
          $ref: "#/components/schemas/MessageRole"
        content:
          description: The content of the message.
          oneOf:
            - type: string
              title: CreateMessageRequestText
              description: The text contents of the message.
            - type: array
              title: CreateMessageRequestContents
              description: An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models/overview).
              items:
                $ref: "#/components/schemas/MessageContent"
              minItems: 1
        attachments:
          description: A list of files attached to the message, and the tools they were added to.
          type: array
          nullable: true
          items:
            $ref: "#/components/schemas/MessageAttachment"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    ModifyMessageRequest:
      type: object
      description: Request object for the Modify message endpoint.
      additionalProperties: false
      properties:
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    DeleteMessageResponse:
      type: object
      properties:
        id:
          type: string
          description: The message identifier.
        deleted:
          type: boolean
          description: Whether the message was deleted.
        object:
          type: string
          description: The object type, which is always `thread.message.deleted`.
          enum: [ thread.message.deleted ]
      required:
        - id
        - object
        - deleted
    ListMessagesResponse:
      type: object
      description: Represents a list of messages returned by the List messages endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of messages.
          items:
            $ref: "#/components/schemas/MessageObject"
        first_id:
          type: string
          description: The ID of the first message in the list.
          example: "msg_abc123"
        last_id:
          type: string
          description: The ID of the last message in the list.
          example: "msg_abc123"
        has_more:
          type: boolean
          description: Whether there are more messages to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    MessageContentImageFileObject:
      type: object
      description: References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.
      properties:
        type:
          type: string
          description: Always `image_file`.
          default: image_file
        image_file:
          $ref: "#/components/schemas/MessageContentImageFile"
      required:
        - image_file
    MessageContentImageFile:
      type: object
      description: The image file that is part of a message.
      properties:
        file_id:
          description: The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.
          type: string
        detail:
          $ref: "#/components/schemas/MessageContentImageDetail"
      required:
        - file_id
    MessageContentImageUrl:
      type: object
      description: The image URL part of a message.
      properties:
        url:
          type: string
          description: "The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."
          format: uri
        detail:
          $ref: "#/components/schemas/MessageContentImageDetail"
      required:
        - url
    MessageContentImageDetail:
      type: string
      description: Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.
      enum: [ "auto", "low", "high" ]
      default: "auto"
    MessageContentTextObject:
      type: object
      description: The text content that is part of a message.
      properties:
        type:
          type: string
          description: Always `text`.
          default: text
        text:
          $ref: "#/components/schemas/MessageContentText"
      required:
        - text
    MessageRequestContentTextObject:
      type: object
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          type: string
        text:
          type: string
          description: Text content to be sent to the model
      required:
        - type
        - text
    MessageContentText:
      type: object
      description: The text content that is part of a message.
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          type: array
          description: A list of annotations that point to specific quotes from specific files.
          items:
            $ref: "#/components/schemas/MessageContentTextAnnotations"
      required:
        - value
    MessageContentTextAnnotations:
      type: object
      description: An annotation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      oneOf:
        - $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject"
        - $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject"
    MessageContentTextAnnotationsFileCitationObject:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files.
      properties:
        type:
          type: string
          description: Always `file_citation`.
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitation"
        start_index:
          type: integer
          description: The start index of the text in the message content that needs to be replaced.
          minimum: 0
        end_index:
          type: integer
          description: The end index of the text in the message content that needs to be replaced.
          minimum: 0
      required:
        - type
        - text
        - file_citation
        - start_index
        - end_index
    MessageContentTextAnnotationsFileCitation:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
      required:
        - file_id
    MessageContentTextAnnotationsFilePathObject:
      type: object
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
      properties:
        type:
          type: string
          description: Always `file_path`.
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          type: object
          title: MessageContentTextAnnotationsFilePath
          properties:
            file_id:
              description: The ID of the file that was generated.
              type: string
          required:
            - file_id
        start_index:
          type: integer
          minimum: 0
        end_index:
          type: integer
          minimum: 0
      required:
        - type
        - text
        - file_path
        - start_index
        - end_index
    MessageDeltaContentImageFileObject:
      type: object
      description: References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          type: string
          description: Always `image_file`.
        image_file:
          $ref: "#/components/schemas/MessageContentImageFile"
      required:
        - index
        - type
    MessageContentImageUrlObject:
      type: object
      description: References an image URL in the content of a message.
      properties:
        type:
          type: string
          description: The type of the content part. Always `image_url`.
          default: image_url
        image_url:
          $ref: "#/components/schemas/MessageContentImageUrl"
      required:
        - image_url
    MessageDeltaContentImageUrlObject:
      type: object
      description: References an image URL in the content of a message.
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          description: Always `image_url`.
          type: string
        image_url:
          $ref: "#/components/schemas/MessageContentImageUrl"
    MessageDeltaContentTextObject:
      type: object
      description: The text content that is part of a message.
      properties:
        index:
          type: integer
          description: The index of the content part in the message.
        type:
          type: string
          description: Always `text`.
        text:
          $ref: "#/components/schemas/MessageDeltaContentText"
      required:
        - index
        - type
    MessageDeltaContentText:
      type: object
      description: The text content that is part of a message.
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          type: array
          description: A list of annotations that point to specific quotes from specific files.
          items:
            $ref: "#/components/schemas/MessageDeltaContentTextAnnotations"
    MessageDeltaContentTextAnnotations:
      type: object
      description: An annotation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      oneOf:
        - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject"
        - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject"
      required:
        - value
        - annotations
    MessageDeltaContentTextAnnotationsFileCitationObject:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "retrieval" tool to search files.
      properties:
        index:
          type: integer
          description: The index of the annotation in the text content part.
        type:
          type: string
          description: Always `file_citation`.
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitation"
        start_index:
          type: integer
          description: The start index of the text in the message content that needs to be replaced.
          minimum: 0
        end_index:
          type: integer
          description: The end index of the text in the message content that needs to be replaced.
          minimum: 0
      required:
        - index
        - type
    MessageDeltaContentTextAnnotationsFileCitation:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
    MessageDeltaContentTextAnnotationsFilePathObject:
      type: object
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
      properties:
        index:
          type: integer
          description: The index of the annotation in the text content part.
        type:
          type: string
          description: Always `file_path`.
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          id: MessageDeltaContentTextAnnotationsFilePath
          type: object
          properties:
            file_id:
              description: The ID of the file that was generated.
              type: string
        start_index:
          type: integer
          minimum: 0
        end_index:
          type: integer
          minimum: 0
      required:
        - index
        - type
    RunStepObject:
      type: object
      description: |
        Represents a step in execution of a run.
      properties:
        id:
          description: The identifier of the run step, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run.step`.
          type: string
          enum: [ "thread.run.step" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) associated with the run step.
          type: string
        thread_id:
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
          type: string
        run_id:
          description: The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that this run step is a part of.
          type: string
        type:
          description: The type of run step, which can be either `message_creation` or `tool_calls`.
          type: string
          title: RunStepType
          enum: [ "message_creation", "tool_calls" ]
        status:
          description: The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.
          type: string
          title: RunStepStatus
          enum: [ "in_progress", "cancelled", "failed", "completed", "expired" ]
        step_details:
          $ref: "#/components/schemas/RunStepDetails"
        last_error:
          type: object
          title: RunStepLastError
          description: The last error associated with this run step. Will be `null` if there are no errors.
          nullable: true
          properties:
            code:
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
              enum: [ "server_error", "rate_limit_exceeded" ]
            message:
              type: string
              description: A human-readable description of the error.
          required:
            - code
            - message
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          type: integer
          nullable: true
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        usage:
          $ref: "#/components/schemas/RunStepCompletionUsage"
      required:
        - id
        - object
        - created_at
        - assistant_id
        - thread_id
        - run_id
        - type
        - status
        - step_details
        - last_error
        - expired_at
        - cancelled_at
        - failed_at
        - completed_at
        - metadata
        - usage
    RunStepDeltaObject:
      type: object
      title: Run step delta object
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming.
      properties:
        id:
          description: The identifier of the run step, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run.step.delta`.
          type: string
          enum: [ "thread.run.step.delta" ]
        delta:
          $ref: "#/components/schemas/RunStepDelta"
      required:
        - id
        - object
        - delta
    RunStepDelta:
      type: object
      description: The delta containing the fields that have changed on the run step.
      properties:
        step_details:
          $ref: "#/components/schemas/RunStepDeltaDetails"
    RunStepDetails:
      type: object
      description: The details of the run step.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsMessageCreationObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsObject"
    RunStepDeltaDetails:
      type: object
      description: The details of the run step
      oneOf:
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject"
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsObject"
    ListRunStepsResponse:
      type: object
      description: Represents a list of run steps returned by the List run steps endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of run steps.
          items:
            $ref: "#/components/schemas/RunStepObject"
        first_id:
          type: string
          description: The ID of the first run step in the list.
          example: "step_abc123"
        last_id:
          type: string
          description: The ID of the last run step in the list.
          example: "step_abc456"
        has_more:
          type: boolean
          description: Whether there are more run steps to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    RunStepDetailsMessageCreationObject:
      type: object
      description: Details of the message creation by the run step.
      properties:
        type:
          type: string
          description: Always `message_creation`.
        message_creation:
          $ref: "#/components/schemas/RunStepDetailsMessageCreation"
      required:
        - type
        - message_creation
    RunStepDetailsMessageCreation:
      type: object
      description: Details of the message creation by the run step.
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step.
      required:
        - message_id
    RunStepDeltaStepDetailsMessageCreationObject:
      type: object
      description: Details of the message creation by the run step.
      properties:
        type:
          type: string
          description: Always `message_creation`.
        message_creation:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreation"
      required:
        - type
    RunStepDeltaStepDetailsMessageCreation:
      type: object
      description: Details of the message creation by the run step.
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step.
    RunStepDetailsToolCallsObject:
      type: object
      description: Details of the tool call.
      properties:
        type:
          type: string
          description: Always `tool_calls`.
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCalls"
      required:
        - type
        - tool_calls
    RunStepDeltaStepDetailsToolCallsObject:
      type: object
      description: Details of the tool call.
      properties:
        type:
          type: string
          description: Always `tool_calls`.
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCalls"
      required:
        - type
    RunStepDetailsToolCalls:
      type: object
      description: Tool calls the run step was involved in.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject"
    RunStepDeltaStepDetailsToolCalls:
      type: object
      description: Tool calls the run step was involved in.
      oneOf:
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject"
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject"
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject"
    RunStepDetailsToolCallsCodeObject:
      type: object
      description: Details of the Code Interpreter tool call the run step was involved in.
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          description: Always `code_interpreter`.
        code_interpreter:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreter"
      required:
        - id
        - type
        - code_interpreter
    RunStepDeltaStepDetailsToolCallsCodeObject:
      type: object
      description: Details of the Code Interpreter tool call the run step was involved in.
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          description: Always `code_interpreter`.
        code_interpreter:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter"
      required:
        - index
        - type
    RunStepDetailsToolCallsCodeObjectCodeInterpreter:
      type: object
      description: The Code Interpreter tool call definition.
      required:
        - input
        - outputs
      properties:
        input:
          type: string
          description: The input to the Code Interpreter tool call.
        outputs:
          type: array
          description: The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutput"
    RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter:
      type: object
      description: The Code Interpreter tool call definition.
        - outputs
      properties:
        input:
          type: string
          description: The input to the Code Interpreter tool call.
        outputs:
          type: array
          description: The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutput"
    RunStepDetailsToolCallsCodeOutput:
      type: object
      description: The output of the Code Interpreter tool call.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject"
    RunStepDeltaStepDetailsToolCallsCodeOutput:
      type: object
      description: The output of the Code Interpreter tool call.
      oneOf:
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject"
        - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject"
    RunStepDetailsToolCallsCodeOutputLogsObject:
      type: object
      description: Text output from the Code Interpreter tool call as part of a run step.
      properties:
        type:
          type: string
          description: Always `logs`.
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
      required:
        - type
        - logs
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      type: object
      description: Text output from the Code Interpreter tool call as part of a run step.
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array.
        type:
          type: string
          description: Always `logs`.
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
      required:
        - index
        - type
    RunStepDetailsToolCallsCodeOutputImageObject:
      type: object
      description: Code Interpreter image output
      properties:
        type:
          type: string
          description: Always `image`.
        image:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImage"
      required:
        - type
        - image
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      type: object
      description: Code interpreter image output
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array.
        type:
          type: string
          description: Always `image`.
        image:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImage"
      required:
        - index
        - type
    RunStepDetailsToolCallsCodeOutputImage:
      type: object
      description: Code interpreter image output.
      properties:
        file_id:
          description: The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.
          type: string
      required:
        - file_id
    RunStepDeltaStepDetailsToolCallsCodeOutputImage:
      type: object
      description: Code interpreter image output.
      properties:
        file_id:
          description: The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.
          type: string
    RunStepDetailsToolCallsFileSearchObject:
      description: File search tool call
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
        file_search:
          type: object
          description: For now, this is always going to be an empty object.
          additionalProperties: true
      required:
        - id
        - type
        - file_search
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      type: object
      description: File search tool call
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search` for this type of tool call.
        file_search:
          type: object
          description: For now, this is always going to be an empty object.
          additionalProperties: true
      required:
        - index
        - type
        - file_search
    RunStepDetailsToolCallsFunctionObject:
      type: object
      description: Function tool call
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: Always `function`.
        function:
          type: object
          title: RunStepDetailsToolCallsFunction
          description: The definition of the function that was called.
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments passed to the function.
            output:
              type: string
              description: The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.
              nullable: true
          required:
            - name
            - arguments
            - output
      required:
        - id
        - type
        - function
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      type: object
      description: Function tool call
      properties:
        index:
          type: integer
          description: The index of the tool call in the tool calls array.
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: Always `function`.
        function:
          type: object
          title: RunStepDeltaStepDetailsToolCallsFunction
          description: The definition of the function that was called.
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments passed to the function.
            output:
              type: string
              description: The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.
              nullable: true
      required:
        - index
        - type
    RunStepCompletionUsage:
      type: object
      description: Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run step.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      nullable: true
    VectorStoreExpirationAfter:
      type: object
      description: The expiration policy for a vector store.
      properties:
        anchor:
          description: "Anchor timestamp after which the expiration policy applies. Supported anchors: `last_active_at`."
          type: string
          enum: [ "last_active_at" ]
        days:
          description: The number of days after the anchor time that the vector store will expire.
          type: integer
          minimum: 1
          maximum: 365
      required:
        - anchor
        - days
    VectorStoreObject:
      type: object
      description: A vector store is a collection of processed files can be used by the `file_search` tool.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `vector_store`.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store was created.
          type: integer
        name:
          description: The name of the vector store.
          type: string
          nullable: true
        usage_bytes:
          description: The total number of bytes used by the files in the vector store.
          type: integer
        file_counts:
          id: VectorStoreFileCounts
          description: The number of files in the vector store.
          type: object
          properties:
            in_progress:
              description: The number of files that are currently being processed.
              type: integer
            completed:
              description: The number of files that have been successfully processed.
              type: integer
            failed:
              description: The number of files that have failed to process.
              type: integer
            cancelled:
              description: The number of files that were cancelled.
              type: integer
            total:
              description: The total number of files.
              type: integer
          required:
            - in_progress
            - completed
            - failed
            - cancelled
            - total
        status:
          description: The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.
          type: string
          name: VectorStoreStatus
          enum: [ "expired", "in_progress", "completed" ]
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        expires_at:
          description: The Unix timestamp (in seconds) for when the vector store will expire.
          type: integer
          nullable: true
        last_active_at:
          description: The Unix timestamp (in seconds) for when the vector store was last active.
          type: integer
          nullable: true
        metadata:
          description: *metadata_description
          type: object
          nullable: true
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - status
        - last_active_at
        - name
        - file_counts
        - metadata
    CreateVectorStoreRequest:
      type: object
      description: Request object for the Create assistant file endpoint.
      additionalProperties: false
      properties:
        name:
          description: The name of the vector store.
          type: string
        file_ids:
          description: A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.
          type: array
          maxItems: 500
          items:
            type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        metadata:
          description: *metadata_description
          type: object
          nullable: true
    UpdateVectorStoreRequest:
      type: object
      description: Request object for the Update vector store endpoint.
      properties:
        name:
          description: The name of the vector store.
          type: string
          nullable: true
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
          nullable: true
        metadata:
          description: *metadata_description
          type: object
          nullable: true
    ListVectorStoresResponse:
      type: object
      description: Represents a list of files returned by the List vector store files endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: A list of assistant files.
          items:
            $ref: "#/components/schemas/VectorStoreObject"
        first_id:
          type: string
          nullable: true
          description: The ID of the first assistant file in the list.
          example: "vs-abc123"
        last_id:
          type: string
          nullable: true
          description: The ID of the last assistant file in the list.
          example: "vs-abc456"
        has_more:
          type: boolean
          description: Whether there are more assistant files available.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    DeleteVectorStoreResponse:
      type: object
      description: Response object for the Delete vector store endpoint.
      properties:
        id:
          type: string
          description: The ID of the deleted vector store.
        deleted:
          type: boolean
          description: Whether the vector store was deleted.
        object:
          type: string
          description: The object type, which is always `vector_store.deleted`.
      required:
        - id
        - object
        - deleted
    VectorStoreFileObject:
      type: object
      description: A list of files attached to a vector store.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `vector_store.file`.
          type: string
        usage_bytes:
          description: The total vector store usage in bytes. Note that this may be different from the original file size.
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store file was created.
          type: integer
        vector_store_id:
          description: The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) that the [File](https://platform.openai.com/docs/api-reference/files) is attached to.
          type: string
        status:
          description: The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.
          type: string
          title: VectorStoreFileStatus
          enum: [ "in_progress", "completed", "cancelled", "failed" ]
        last_error:
          id: VectorStoreFileLastError
          type: object
          description: The last error associated with this vector store file. Will be `null` if there are no errors.
          nullable: true
          properties:
            code:
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
              enum:
                [
                  "internal_error",
                  "file_not_found",
                  "parsing_error",
                  "unhandled_mime_type",
                ]
            message:
              type: string
              description: A human-readable description of the error.
          required:
            - code
            - message
      required:
        - id
        - object
        - usage_bytes
        - created_at
        - vector_store_id
        - status
        - last_error
    CreateVectorStoreFileRequest:
      type: object
      description: Request object for the Create vector store file endpoint.
      properties:
        file_id:
          description: A [File](https://platform.openai.com/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.
          type: string
      required:
        - file_id
    ListVectorStoreFilesResponse:
      type: object
      description: Represents a list of message files returned by the List vector store files endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: A list of message files.
          items:
            $ref: "#/components/schemas/VectorStoreFileObject"
        first_id:
          type: string
          description: The ID of the first message file in the list.
          example: "file-abc123"
        last_id:
          type: string
          description: The ID of the last message file in the list.
          example: "file-abc456"
        has_more:
          type: boolean
          description: Whether there are more message files available.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    DeleteVectorStoreFileResponse:
      type: object
      description: Response object for the Delete vector store file endpoint.
      properties:
        id:
          type: string
          description: The ID of the deleted vector store file.
        deleted:
          type: boolean
          description: Whether the vector store file was deleted.
        object:
          type: string
          description: The object type, which is always `vector_store.file.deleted`.
      required:
        - id
        - object
        - deleted
    VectorStoreFileBatchObject:
      type: object
      description: A batch of files attached to a vector store.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `vector_store.file_batch`.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store files batch was created.
          type: integer
        vector_store_id:
          description: The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) that the [File](https://platform.openai.com/docs/api-reference/files) is attached to.
          type: string
        status:
          description: The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.
          type: string
          enum: [ "in_progress", "completed", "cancelled", "failed" ]
        file_counts:
          type: object
          description: The number of files per status.
          properties:
            in_progress:
              description: The number of files that are currently being processed.
              type: integer
            completed:
              description: The number of files that have been processed.
              type: integer
            failed:
              description: The number of files that have failed to process.
              type: integer
            cancelled:
              description: The number of files that where cancelled.
              type: integer
            total:
              description: The total number of files.
              type: integer
          required:
            - in_progress
            - completed
            - cancelled
            - failed
            - total
      required:
        - id
        - object
        - created_at
        - vector_store_id
        - status
        - file_counts
    CreateVectorStoreFileBatchRequest:
      type: object
      description: Request object for the Create vector store file batch endpoint.
      properties:
        file_ids:
          description: A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.
          type: array
          minItems: 1
          maxItems: 500
          items:
            type: string
      required:
        - file_ids
    AssistantStreamEvent:
      type: object
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming.
      oneOf:
        - $ref: "#/components/schemas/ThreadStreamEvent"
        - $ref: "#/components/schemas/RunStreamEvent"
        - $ref: "#/components/schemas/RunStepStreamEvent"
        - $ref: "#/components/schemas/RunStepStreamDeltaEvent"
        - $ref: "#/components/schemas/MessageStreamEvent"
        - $ref: "#/components/schemas/MessageStreamDeltaEvent"
        - $ref: "#/components/schemas/ErrorEvent"
        - $ref: "#/components/schemas/DoneEvent"
      discriminator:
        propertyName: event
    EventType:
      type: string
      description: The type of the event.
      enum:
        - thread.created
        - thread.run.created
        - thread.run.queued
        - thread.run.in_progress
        - thread.run.requires_action
        - thread.run.completed
        - thread.run.failed
        - thread.run.cancelling
        - thread.run.cancelled
        - thread.run.expired
        - thread.run.step.created
        - thread.run.step.in_progress
        - thread.run.step.delta
        - thread.run.step.completed
        - thread.run.step.failed
        - thread.run.step.cancelled
        - thread.run.step.expired
        - thread.message.created
        - thread.message.in_progress
        - thread.message.delta
        - thread.message.completed
        - thread.message.failed
        - error
        - done
    ThreadStreamEvent:
      type: object
      description: Occurs when a new [thread](https://platform.openai.com/docs/api-reference/threads/object) is created.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/ThreadObject"
      required:
        - event
        - data
    RunStreamEvent:
      type: object
      description: Occurs when a new [run](https://platform.openai.com/docs/api-reference/runs/object) changes state.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/RunObject"
      required:
        - event
        - data
    RunStepStreamEvent:
      type: object
      description: Occurs when a new [run step](https://platform.openai.com/docs/api-reference/runs/step-object) changes state.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
        - event
        - data
    RunStepStreamDeltaEvent:
      type: object
      description: Occurs when a new [run step](https://platform.openai.com/docs/api-reference/runs/step-object) changes state.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/RunStepDeltaObject"
      required:
        - event
        - data
    MessageStreamEvent:
      type: object
      description: Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) changes state.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
        - event
        - data
    MessageStreamDeltaEvent:
      type: object
      description: Occurs when a [message](https://platform.openai.com/docs/api-reference/messages/object) changes state.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/MessageDeltaObject"
      required:
        - event
        - data
    ErrorEvent:
      type: object
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          $ref: "#/components/schemas/Error"
      required:
        - event
        - data
      description: Occurs when an [error](https://platform.openai.com/docs/guides/error-codes/api-errors) occurs. This can happen due to an internal server error or a timeout.
    DoneEvent:
      type: object
      description: Occurs when a stream ends.
      properties:
        event:
          $ref: "#/components/schemas/EventType"
        data:
          type: string
      required:
        - event
        - data
    Error:
      type: object
      description: Represents an error that occurred during an API request.
      properties:
        code:
          type: string
          description: The error code.
          nullable: true
        message:
          type: string
          description: A human-readable description of the error.
          nullable: false
        param:
          type: string
          description: The parameter in the request that caused the error.
          nullable: true
        type:
          type: string
          description: The type of error.
          nullable: false
      required:
        - type
        - message
        - param
        - code
    CreateBatchRequest:
      type: object
      description: |
        Represents a request to create a new batch.
      required:
        - input_file_id
        - endpoint
        - completion_window
      properties:
        input_file_id:
          type: string
          description: |
            The ID of an uploaded file that contains requests for the new batch.
            
            See [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.
            
            Your input file must be formatted as a [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 100 MB in size.
        endpoint:
          $ref: "#/components/schemas/BatchEndpoint"
        completion_window:
          $ref: "#/components/schemas/BatchCompletionWindow"
        metadata:
          type: object
          additionalProperties:
            type: string
          description: Optional custom metadata for the batch.
          nullable: true
    BatchEndpoint:
      type: string
      enum:
        [
          "/v1/chat/completions",
          "/v1/embeddings",
          "/v1/completions",
        ]
      description: The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.
    BatchCompletionWindow:
      type: string
      enum: [ "24h" ]
      description: The time frame within which the batch should be processed. Currently only `24h` is supported.
    Batch:
      type: object
      description: Represents a batch of requests.
      properties:
        id:
          type: string
        object:
          type: string
          enum: [ batch ]
          description: The object type, which is always `batch`.
        endpoint:
          $ref: "#/components/schemas/BatchEndpoint"
        errors:
          id: BatchErrors
          type: object
          properties:
            object:
              type: string
              description: The object type, which is always `list`.
            data:
              type: array
              items:
                id: BatchError
                type: object
                properties:
                  code:
                    type: string
                    description: An error code identifying the error type.
                  message:
                    type: string
                    description: A human-readable message providing more details about the error.
                  param:
                    type: string
                    description: The name of the parameter that caused the error, if applicable.
                    nullable: true
                  line:
                    type: integer
                    description: The line number of the input file where the error occurred, if applicable.
                    nullable: true
        input_file_id:
          type: string
          description: The ID of the input file for the batch.
        completion_window:
          $ref: "#/components/schemas/BatchCompletionWindow"
        status:
          type: string
          description: The current status of the batch.
          enum:
            - validating
            - failed
            - in_progress
            - finalizing
            - completed
            - expired
            - cancelling
            - cancelled
        output_file_id:
          type: string
          description: The ID of the file containing the outputs of successfully executed requests.
        error_file_id:
          type: string
          description: The ID of the file containing the outputs of requests with errors.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was created.
        in_progress_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started processing.
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch will expire.
        finalizing_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started finalizing.
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was completed.
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch failed.
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch expired.
        cancelling_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started cancelling.
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
        request_counts:
          id: BatchRequestCounts
          type: object
          properties:
            total:
              type: integer
              description: Total number of requests in the batch.
            completed:
              type: integer
              description: Number of requests that have been completed successfully.
            failed:
              type: integer
              description: Number of requests that have failed.
          required:
            - total
            - completed
            - failed
          description: The request counts for different statuses within the batch.
        metadata:
          description: *metadata_description
          type: object
          nullable: true
      required:
        - id
        - object
        - endpoint
        - input_file_id
        - completion_window
        - status
        - created_at
      BatchRequestInput:
        type: object
        description: The per-line object of the batch input file
        properties:
          custom_id:
            type: string
            description: A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.
          method:
            type: string
            enum: [ "POST" ]
            description: The HTTP method to be used for the request. Currently only `POST` is supported.
          url:
            type: string
            description: The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.
      BatchRequestOutput:
        type: object
        description: The per-line object of the batch output and error files
        properties:
          id:
            type: string
            description: The ID of the request.
          custom_id:
            type: string
            description: A developer-provided per-request id that will be used to match outputs to inputs.
          response:
            id: BatchRequestOutputResponse
            type: object
            description: The response object for the request.
            nullable: true
            properties:
              status_code:
                type: integer
                description: The HTTP status code of the response
              request_id:
                type: string
                description: An unique identifier for the OpenAI API request. Please include this request ID when contacting support.
              body:
                type: object
                x-oaiTypeLabel: map
                description: The JSON body of the response
          error:
            id: BatchRequestOutputError
            type: object
            nullable: true
            description: For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.
            properties:
              code:
                type: string
                description: A machine-readable error code.
              message:
                type: string
                description: A human-readable error message.
    ListBatchesResponse:
      type: object
      description: Represents a list of batches returned by the List batches endpoint.
      properties:
        data:
          type: array
          items:
            $ref: "#/components/schemas/Batch"
        first_id:
          type: string
          description: The ID of the first batch in the list.
          example: "batch_abc123"
        last_id:
          type: string
          description: The ID of the last batch in the list.
          example: "batch_abc456"
        has_more:
          type: boolean
          description: Whether there are more batches available.
        object:
          type: string
          description: The object type, which is always `list`.
          enum: [ list ]
      required:
        - object
        - data
        - has_more

security:
  - ApiKeyAuth: [ ]
