#file: noinspection YAMLUnusedAnchor, YAMLSchemaValidation
openapi: 3.0.0

info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  version: "2.0.0"
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE

servers:
  - url: https://api.openai.com/v1

tags:
  - name: Assistants
    description: Build Assistants that can call models and use tools.
  - name: Chat
    description: Given a list of messages comprising a conversation, the model will return a response.
  - name: Completions
    description: Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.
  - name: Embeddings
    description: Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
  - name: Fine-tuning
    description: Manage fine-tuning jobs to tailor a model to your specific training data.
  - name: Images
    description: Given a prompt and/or an input image, the model will generate a new image.
  - name: Models
    description: List and describe the various models available in the API.
  - name: Moderations
    description: Given a input text, outputs if the model classifies it as violating OpenAI's content policy.

paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: Creates a model response for the given chat conversation.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
  /completions:
    post:
      operationId: createCompletion
      tags:
        - Completions
      summary: Creates a completion for the provided prompt and parameters.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateCompletionResponse"
  /embeddings:
    post:
      operationId: createEmbedding
      tags:
        - Embeddings
      summary: Creates an embedding vector representing the input text.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEmbeddingRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateEmbeddingResponse"
  /fine_tuning/jobs:
    post:
      operationId: createFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateFineTuningJobRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
    get:
      operationId: listPaginatedFineTuningJobs
      tags:
        - Fine-tuning
      summary: |
        List your organization's fine-tuning jobs.
      parameters:
        - name: after
          in: query
          description: Identifier for the last job from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of fine-tuning jobs to retrieve.
          required: false
          schema:
            type: integer
            default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListPaginatedFineTuningJobsResponse"
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: retrieveFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: listFineTuningEvents
      tags:
        - Fine-tuning
      summary: |
        Get status updates for a fine-tuning job.
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job to get events for.
        - name: after
          in: query
          description: Identifier for the last event from the previous pagination request.
          required: false
          schema:
            type: string
        - name: limit
          in: query
          description: Number of events to retrieve.
          required: false
          schema:
            type: integer
            default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFineTuningJobEventsResponse"
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: cancelFineTuningJob
      tags:
        - Fine-tuning
      summary: |
        Immediately cancel a fine-tune job.
      parameters:
        - in: path
          name: fine_tuning_job_id
          required: true
          schema:
            type: string
            example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the fine-tuning job to cancel.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FineTuningJob"
  /images/generations:
    post:
      operationId: createImage
      tags:
        - Images
      summary: Creates an image given a prompt.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateImageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
  /models:
    get:
      operationId: listModels
      tags:
        - Models
      summary: Lists the currently available models, and provides basic information about each one such as the owner and availability.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListModelsResponse"
  /models/{model}:
    get:
      operationId: retrieveModel
      tags:
        - Models
      summary: Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
      parameters:
        - in: path
          name: model
          required: true
          schema:
            type: string
            # ideally this will be an actual ID, so this will always work from browser
            example: gpt-3.5-turbo
          description: The ID of the model to use for this request
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Model"
    delete:
      operationId: deleteModel
      tags:
        - Models
      summary: Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.
      parameters:
        - in: path
          name: model
          required: true
          schema:
            type: string
            example: ft:gpt-3.5-turbo:acemeco:suffix:abc123
          description: The model to delete
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteModelResponse"
  /moderations:
    post:
      operationId: createModeration
      tags:
        - Moderations
      summary: Classifies if text violates OpenAI's Content Policy.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateModerationRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateModerationResponse"
  /assistants:
    get:
      operationId: listAssistants
      tags:
        - Assistants
      summary: Returns a list of assistants.
      parameters:
        - name: limit
          in: query
          description: &pagination_limit_param_description |
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: &pagination_order_param_description |
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: &pagination_after_param_description |
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: &pagination_before_param_description |
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListAssistantsResponse"
    post:
      operationId: createAssistant
      tags:
        - Assistants
      summary: Create an assistant with a model and instructions.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateAssistantRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
  /assistants/{assistant_id}:
    get:
      operationId: getAssistant
      tags:
        - Assistants
      summary: Retrieves an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
    post:
      operationId: modifyAssistant
      tags:
        - Assistant
      summary: Modifies an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyAssistantRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantObject"
    delete:
      operationId: deleteAssistant
      tags:
        - Assistants
      summary: Delete an assistant.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteAssistantResponse"
  /threads:
    post:
      operationId: createThread
      tags:
        - Assistants
      summary: Create a thread.
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
  /threads/{thread_id}:
    get:
      operationId: getThread
      tags:
        - Assistants
      summary: Retrieves a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
    post:
      operationId: modifyThread
      tags:
        - Assistants
      summary: Modifies a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to modify. Only the `metadata` can be modified.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyThreadRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThreadObject"
    delete:
      operationId: deleteThread
      tags:
        - Assistants
      summary: Delete a thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteThreadResponse"
  /threads/{thread_id}/messages:
    get:
      operationId: listThreadMessages
      tags:
        - Assistants
      summary: Returns a list of messages for a given thread.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) the messages belong to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListMessagesResponse"
    post:
      operationId: createThreadMessage
      tags:
        - Assistants
      summary: Create a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to create a message for.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateMessageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
  /threads/{thread_id}/messages/{message_id}:
    get:
      operationId: getThreadMessage
      tags:
        - Assistants
      summary: Retrieve a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
    post:
      operationId: modifyThreadMessage
      tags:
        - Assistants
      summary: Modifies a message.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyMessageRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageObject"
  /threads/runs:
    post:
      operationId: createThreadAndRun
      tags:
        - Assistants
      summary: Create a thread and run it in one request.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateThreadAndRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs:
    get:
      operationId: listThreadRuns
      tags:
        - Assistants
      summary: Returns a list of runs belonging to a thread.
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run belongs to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunsResponse"
    post:
      operationId: createThreadRun
      tags:
        - Assistants
      summary: Create a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to run.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getThreadRun
      tags:
        - Assistants
      summary: Retrieves a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
    post:
      operationId: modifyThreadRun
      tags:
        - Assistants
      summary: Modifies a run.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModifyRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitThreadToolOutputsToRun
      tags:
        - Assistants
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this run belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run that requires the tool output submission.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SubmitToolOutputsRunRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelThreadRun
      tags:
        - Assistants
      summary: Cancels a run that is `in_progress`.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this run belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to cancel.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunObject"
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listThreadRunSteps
      tags:
        - Assistants
      summary: Returns a list of run steps belonging to a run.
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run and run steps belong to.
        - name: run_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the run the run steps belong to.
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListRunStepsResponse"
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getThreadRunStep
      tags:
        - Assistants
      summary: Retrieves a run step.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which the run and run step belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to which the run step belongs.
        - in: path
          name: step_id
          required: true
          schema:
            type: string
          description: The ID of the run step to retrieve.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RunStepObject"
  /assistants/{assistant_id}/files:
    get:
      operationId: listAssistantFiles
      tags:
        - Assistants
      summary: Returns a list of assistant files.
      parameters:
        - name: assistant_id
          in: path
          description: The ID of the assistant the file belongs to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListAssistantFilesResponse"
    post:
      operationId: createAssistantFile
      tags:
        - Assistants
      summary: Create an assistant file by attaching a [File](https://platform.openai.com/docs/api-reference/files) to an [assistant](https://platform.openai.com/docs/api-reference/assistants).
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
            example: file-AF1WoRqd3aJAHsqc9NY7iL8F
          description: |
            The ID of the assistant for which to create a File.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateAssistantFileRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantFileObject"
  /assistants/{assistant_id}/files/{file_id}:
    get:
      operationId: getAssistantFile
      tags:
        - Assistants
      summary: Retrieves an AssistantFile.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant who the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
          description: The ID of the file we're getting.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AssistantFileObject"
    delete:
      operationId: deleteAssistantFile
      tags:
        - Assistants
      summary: Delete an assistant file.
      parameters:
        - in: path
          name: assistant_id
          required: true
          schema:
            type: string
          description: The ID of the assistant that the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
          description: The ID of the file to delete.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteAssistantFileResponse"
  /threads/{thread_id}/messages/{message_id}/files:
    get:
      operationId: listThreadMessageFiles
      tags:
        - Assistants
      summary: Returns a list of message files.
      parameters:
        - name: thread_id
          in: path
          description: The ID of the thread that the message and files belong to.
          required: true
          schema:
            type: string
        - name: message_id
          in: path
          description: The ID of the message that the files belongs to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: *pagination_limit_param_description
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: *pagination_order_param_description
          schema:
            type: string
            default: desc
            enum: [ "asc", "desc" ]
        - name: after
          in: query
          description: *pagination_after_param_description
          schema:
            type: string
        - name: before
          in: query
          description: *pagination_before_param_description
          schema:
            type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListMessageFilesResponse"
  /threads/{thread_id}/messages/{message_id}/files/{file_id}:
    get:
      operationId: getThreadMessageFile
      tags:
        - Assistants
      summary: Retrieves a message file.
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
            example: thread_AF1WoRqd3aJAHsqc9NY7iL8F
          description: The ID of the thread to which the message and File belong.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
            example: msg_AF1WoRqd3aJAHsqc9NY7iL8F
          description: The ID of the message the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
            example: file-AF1WoRqd3aJAHsqc9NY7iL8F
          description: The ID of the file being retrieved.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessageFileObject"
components:

  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: 'bearer'

  schemas:
    CreateCompletionRequest:
      type: object
      description: Request object for the Create completion endpoint.
      properties:
        model:
          title: CompletionModel
          description: &model_description |
            ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models/overview) for descriptions of them.
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: CompletionModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "gpt-3.5-turbo-instruct", "davinci-002", "babbage-002" ]
        prompt:
          title: CompletionPrompt
          description: &completions_prompt_description |
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
          default: "<|endoftext|>"
          nullable: true
          oneOf:
            - type: string
              description: A string prompt.
              default: ""
              example: "This is a test."
            - type: array
              description: A list of string prompts.
              items:
                type: string
                default: ""
                example: "This is a test."
            - type: array
              description: A tokenized prompt.
              minItems: 1
              items:
                type: integer
              example: "[1212, 318, 257, 1332, 13]"
            - type: array
              description: A list of tokenized prompts.
              minItems: 1
              items:
                type: array
                minItems: 1
                items:
                  type: integer
              example: "[[1212, 318, 257, 1332, 13]]"
        best_of:
          type: integer
          # default: 1 # Creates issues
          minimum: 0
          maximum: 20
          nullable: true
          description: &completions_best_of_description |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.
            
            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return â€“ `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
        echo:
          type: boolean
          default: false
          nullable: true
          description: &completions_echo_description >
            Echo back the prompt in addition to the completion
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: &completions_frequency_penalty_description |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)
        logit_bias: &completions_logit_bias
          type: object
          default: null
          nullable: true
          additionalProperties:
            type: integer
          description: &completions_logit_bias_description |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
        logprobs: &completions_logprobs_configuration
          type: integer
          minimum: 0
          maximum: 5
          default: null
          nullable: true
          description: &completions_logprobs_description |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
        max_tokens:
          type: integer
          minimum: 0
          default: 16
          example: 16
          nullable: true
          description: &completions_max_tokens_description |
            The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
        n:
          type: integer
          minimum: 1
          maximum: 128
          default: 1
          example: 1
          nullable: true
          description: &completions_completions_description |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: &completions_presence_penalty_description |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)
        seed: &completions_seed_param
          type: integer
          # minimum: -9223372036854775808 # The value can't be represented exactly in JavaScript
          # maximum: 9223372036854775807
          nullable: true
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
        stop:
          title: CompletionStop
          description: &completions_stop_description >
            Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
          default: null
          nullable: true
          oneOf:
            - type: string
              description: A string stop sequence.
              default: <|endoftext|>
              example: "\n"
              nullable: true
            - type: array
              description: A list of string stop sequences.
              minItems: 1
              maxItems: 4
              items:
                type: string
                example: '["\n"]'
        stream:
          description: >
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
          default: false
        suffix:
          description: The suffix that comes after a completion of inserted text.
          default: null
          nullable: true
          type: string
          example: "test."
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: &completions_temperature_description |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: &completions_top_p_description |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
        user: &end_user_param_configuration
          type: string
          example: user-1234
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).
      required:
        - model
        - prompt
    CreateCompletionResponse:
      type: object
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      properties:
        id:
          type: string
          description: A unique identifier for the completion.
        choices:
          type: array
          description: The list of completion choices the model generated for the input prompt.
          items:
            $ref: "#/components/schemas/CompletionChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was created.
        model:
          type: string
          description: The model used for completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always "text_completion"
          enum: [ text_completion ]
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - id
        - object
        - created
        - model
        - choices
    CompletionChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - finish_reason
        - index
        - logprobs
        - text
      properties:
        finish_reason:
          $ref: "#/components/schemas/CompletionFinishReason"
        index:
          type: integer
          description: The index of the choice in the list of generated choices.
        logprobs:
          $ref: "#/components/schemas/CompletionLogprobs"
          nullable: true
        text:
          type: string
          description: The text of the completion.
    CompletionFinishReason:
      type: string
      nullable: true
      description: &completion_finish_reason_description |
        The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        `length` if the maximum number of tokens specified in the request was reached,
        or `content_filter` if content was omitted due to a flag from our content filters.
      enum: [ "stop", "length", "content_filter" ]
    CompletionLogprobs:
      type: object
      description: |
        The probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
      properties:
        text_offset:
          type: array
          description: The offset of the token from the beginning of the prompt.
          items:
            type: integer
        token_logprobs:
          type: array
          description: The log probabilities of tokens in the completion.
          items:
            type: number
            nullable: true
        tokens:
          type: array
          description: The tokens generated by the model converted back to text.
          items:
            type: string
        top_logprobs:
          type: array
          description: The log probabilities of the `logprobs` most likely tokens.
          items:
            type: object
            nullable: true
            additionalProperties:
              type: number
    CreateChatCompletionRequest:
      type: object
      description: Request object for the Create chat completion endpoint.
      properties:
        model:
          title: ChatCompletionModel
          description: ID of the model to use. See the [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.
          example: "gpt-3.5-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ChatCompletionModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum:
                [
                  "gpt-4",
                  "gpt-4-0314",
                  "gpt-4-0613",
                  "gpt-4-32k",
                  "gpt-4-32k-0314",
                  "gpt-4-32k-0613",
                  "gpt-4-turbo-preview",
                  "gpt-4-1106-preview",
                  "gpt-4-0125-preview",
                  "gpt-4-vision-preview",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-0613",
                  "gpt-3.5-turbo-1106",
                  "gpt-3.5-turbo-16k-0613",
                ]
        messages:
          description: A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
          type: array
          minItems: 1
          items:
            $ref: "#/components/schemas/ChatCompletionMessage"
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: *completions_frequency_penalty_description
        logit_bias:
          type: object
          default: null
          nullable: true
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        logprobs:
          description: Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. This option is currently not available on the `gpt-4-vision-preview` model.
          type: boolean
          nullable: true
        top_logprobs:
          description: An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.
          type: integer
          minimum: 0
          maximum: 5
          nullable: true
        max_tokens:
          description: |
            The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in the chat completion.

            The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          type: integer
          nullable: true
        n:
          type: integer
          minimum: 1
          maximum: 128
          default: 1
          example: 1
          nullable: true
          description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: *completions_presence_penalty_description
        response_format:
          title: ChatCompletionResponseFormat
          type: object
          description: |
            An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and `gpt-3.5-turbo-1106`.

            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

            **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
          properties:
            type:
              type: string
              enum: [ "text", "json_object" ]
              example: "json_object"
              default: "text"
              description: Must be one of `text` or `json_object`.
        seed:
          type: integer
          # minimum: -9223372036854775808 # The value can't be represented exactly in JavaScript
          # maximum: 9223372036854775807
          nullable: true
          description: |
            This feature is in Beta. 
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
        stop:
          title: ChatCompletionStop
          description: |
            Up to 4 sequences where the API will stop generating further tokens.
          default: null
          oneOf:
            - type: string
              description: A string stop sequence.
              nullable: true
            - type: array
              description: A list of string stop sequences.
              minItems: 1
              maxItems: 4
              items:
                type: string
        stream:
          description: >
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          type: boolean
          nullable: true
          default: false
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          example: 1
          nullable: true
          description: *completions_temperature_description
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          example: 1
          nullable: true
          description: *completions_top_p_description
        tools:
          type: array
          description: >
            A list of tools the model may call. Currently, only functions are supported as a tool.
            Use this to provide a list of functions the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
        tool_choice:
          title: ChatCompletionToolChoiceOption
          description: |
            Controls which (if any) function is called by the model.
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
            Specifying a particular function via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that function.
            
            `none` is the default when no functions are present. `auto` is the default if functions are present.
          oneOf:
            - type: string
              title: ChatCompletionToolChoiceMode
              description: >
                `none` means the model will not call a function and instead generates a message.
                `auto` means the model can pick between generating a message or calling a function.
              enum: [ none, auto ]
            - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
        user: *end_user_param_configuration
        function_call:
          title: ChatCompletionFunctionCall
          deprecated: true
          description: |
            Deprecated in favor of `tool_choice`.
            
            Controls which (if any) function is called by the model.
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
            Specifying a particular function via [ChatCompletionFunctionCallOption] forces the model to call that function.
            
            `none` is the default when no functions are present. `auto` is the default if functions are present.
          oneOf:
            - type: string
              title: ChatCompletionFunctionCallMode
              description: >
                `none` means the model will not call a function and instead generates a message.
                `auto` means the model can pick between generating a message or calling a function.
              enum: [ none, auto ]
            - $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
        functions:
          deprecated: true
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for.
          type: array
          minItems: 1
          maxItems: 128
          items:
            $ref: "#/components/schemas/FunctionObject"
      required:
        - model
        - messages
    ChatCompletionMessage:
      type: object
      description: A message in a chat conversation.
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionSystemMessage"
        - $ref: "#/components/schemas/ChatCompletionUserMessage"
        - $ref: "#/components/schemas/ChatCompletionAssistantMessage"
        - $ref: "#/components/schemas/ChatCompletionToolMessage"
        - $ref: "#/components/schemas/ChatCompletionFunctionMessage"
      discriminator:
        propertyName: role
    ChatCompletionSystemMessage:
      type: object
      description: A system message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: system
          description: The role of the messages author, in this case `system`.
        content:
          description: The contents of the system message.
          type: string
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
    ChatCompletionUserMessage:
      type: object
      description: A user message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: user
          description: The role of the messages author, in this case `user`.
        content:
          # TODO extract to ChatCompletionMessageContent once generator bug fixed
          description: The contents of the user message.
          oneOf:
            - type: string
              description: The text contents of the message.
            - type: array
              description: An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Image input is only supported when using the `gpt-4-vision-preview` model.
              items:
                $ref: "#/components/schemas/ChatCompletionMessageContentPart"
              minItems: 1
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
    ChatCompletionAssistantMessage:
      type: object
      description: An assistant message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: assistant
          description: The role of the messages author, in this case `assistant`.
        content:
          nullable: true
          type: string
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
          description: The tools that should be called, as generated by the model.
        function_call:
          $ref: "#/components/schemas/ChatCompletionMessageFunctionCall"
          deprecated: true
          description: "Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model."
    ChatCompletionToolMessage:
      type: object
      description: A tool message in a chat conversation.
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: tool
          description: The role of the messages author, in this case `tool`.
        content:
          type: string
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      required:
        - content
        - tool_call_id
    ChatCompletionFunctionMessage:
      type: object
      description: A function message in a chat conversation.
      deprecated: true
      properties:
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
          default: function
          description: The role of the messages author, in this case `function`.
        content:
          type: string
          description: The contents of the function message.
          nullable: true
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
        - content
    ChatCompletionMessageContentPart:
      description: A content part of a user message.
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionMessageContentPartImage"
      discriminator:
        propertyName: type
    ChatCompletionMessageContentPartText:
      type: object
      description: A text content part of a user message.
      properties:
        type:
          $ref: "#/components/schemas/ChatCompletionMessageContentPartType"
          default: text
          description: The type of the content part, in this case `text`.
        text:
          type: string
          description: The text content.
      required:
        - text
    ChatCompletionMessageContentPartImage:
      type: object
      title: Image content part
      properties:
        type:
          $ref: "#/components/schemas/ChatCompletionMessageContentPartType"
          default: image_url
          description: The type of the content part, in this case `image_url`.
        image_url:
          title: ChatCompletionMessageImageUrl
          description: The URL of the image.
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              type: string
              title: ChatCompletionMessageImageDetail
              description: Specifies the detail level of the image. Learn more in the [Vision guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding).
              enum: [ "auto", "low", "high" ]
              default: "auto"
          required:
            - url
      required:
        - image_url
    ChatCompletionMessageContentPartType:
      type: string
      enum: [ "text", "image_url" ]
      description: The type of the content part.
    ChatCompletionMessageRole:
      type: string
      description: The role of the messages author. One of `system`, `user`, `assistant`, or `tool` (`function` is deprecated).
      enum: [ "system", "user", "assistant", "tool", "function" ]
    ChatCompletionMessageFunctionCall:
      type: object
      description: The name and arguments of a function that should be called, as generated by the model.
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
      required:
        - name
        - arguments
    ChatCompletionFunctionCallOption:
      type: object
      description: Forces the model to call the specified function.
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
    FunctionObject:
      type: object
      description: A function that the model may call.
      properties:
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
      required:
        - name
    FunctionParameters:
      type: object
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
      additionalProperties: true
    ChatCompletionTool:
      type: object
      description: A tool the model may use.
      properties:
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - type
        - function
    ChatCompletionNamedToolChoice:
      type: object
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
      properties:
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
      required:
        - type
        - function
    ChatCompletionMessageToolCalls:
      type: array
      description: The tool calls generated by the model, such as function calls.
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"
    ChatCompletionMessageToolCall:
      type: object
      description: A tool call generated by the model, such as a function call.
      properties:
        # TODO: index included when streaming
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionMessageFunctionCall"
      required:
        - id
        - type
        - function
    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          items:
            $ref: "#/components/schemas/ChatCompletionResponseChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          # enum: [ chat.completion ] # Anyscale API sends `text_completion` instead
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - choices
        - created
        # - id # Made nullable to support OpenRouter API which doesn't return this field with some models
        - model
        - object
    ChatCompletionResponseChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - finish_reason
        # - index # Made nullable to support OpenRouter API which doesn't return this field
        - message
        - logprobs
      properties:
        finish_reason:
          $ref: "#/components/schemas/ChatCompletionFinishReason"
          nullable: true
        index:
          type: integer
          description: The index of the choice in the list of choices.
        message:
          $ref: "#/components/schemas/ChatCompletionAssistantMessage"
        logprobs:
          $ref: "#/components/schemas/ChatCompletionLogprobs"
    ChatCompletionFinishReason:
      type: string
      description: &chat_completion_finish_reason_description |
        The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        `length` if the maximum number of tokens specified in the request was reached,
        `content_filter` if content was omitted due to a flag from our content filters,
        `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
      enum:
        [
          "stop",
          "length",
          "tool_calls",
          "content_filter",
          "function_call",
        ]
    ChatCompletionLogprobs: &chat_completion_response_logprobs
      description: Log probability information for the choice.
      type: object
      nullable: true
      properties:
        content:
          description: A list of message content tokens with log probability information.
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob"
          nullable: true
      required:
        - content
    ChatCompletionTokenLogprob:
      type: object
      description: Log probability information for a token.
      properties:
        token: &chat_completion_response_logprobs_token
          description: The token.
          type: string
        logprob: &chat_completion_response_logprobs_token_logprob
          description: The log probability of this token.
          type: number
        bytes: &chat_completion_response_logprobs_bytes
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          type: array
          items:
            type: integer
          nullable: true
        top_logprobs:
          description: List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionTokenTopLogprob"
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
    ChatCompletionTokenTopLogprob:
      type: object
      description: Most likely tokens and their log probability, at this token position.
      properties:
        token: *chat_completion_response_logprobs_token
        logprob: *chat_completion_response_logprobs_token_logprob
        bytes: *chat_completion_response_logprobs_bytes
      required:
        - token
        - logprob
        - bytes
    CreateChatCompletionStreamResponse:
      type: object
      description: Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has the same ID.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          items:
            $ref: "#/components/schemas/ChatCompletionStreamResponseChoice"
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
        model:
          type: string
          description: The model to generate the completion.
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact
        object:
          type: string
          description: The object type, which is always `chat.completion.chunk`.
          # enum: [ chat.completion.chunk ] # OpenRouter API sends `chat.completion` instead
      required:
        - choices
        - created
        # - id # Made nullable to support OpenRouter API which doesn't return this field with some models
        # - model # Made nullable to support TogetherAI API which doesn't return this field with some models
        - object
    ChatCompletionStreamResponseChoice:
      type: object
      description: A choice the model generated for the input prompt.
      required:
        - delta
        - finish_reason
        # - index # Made nullable to support OpenRouter API which doesn't return this field
      properties:
        delta:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta"
        logprobs: *chat_completion_response_logprobs
        finish_reason:
          $ref: "#/components/schemas/ChatCompletionFinishReason"
          nullable: true
        index:
          type: integer
          description: The index of the choice in the list of choices.
    ChatCompletionStreamResponseDelta:
      type: object
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          type: string
          description: The contents of the chunk message.
          nullable: true
        function_call:
          $ref: "#/components/schemas/ChatCompletionStreamMessageFunctionCall"
        tool_calls:
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionStreamMessageToolCallChunk"
        role:
          $ref: "#/components/schemas/ChatCompletionMessageRole"
    ChatCompletionStreamMessageFunctionCall:
      type: object
      description: The name and arguments of a function that should be called, as generated by the model.
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
    ChatCompletionStreamMessageToolCallChunk:
      type: object
      description: The tool that should be called, as generated by the model.
      properties:
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum: [ "function" ]
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/ChatCompletionStreamMessageFunctionCall"
      required:
        - index
    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          type: integer
          nullable: true
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    CreateEmbeddingRequest:
      type: object
      description: Request object for the Create embedding endpoint.
      additionalProperties: false
      properties:
        model:
          title: EmbeddingModel
          description: *model_description
          example: "text-embedding-3-small"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: EmbeddingModels
              description: |
                Available completion models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large" ]
        input:
          title: EmbeddingInput
          description: |
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          example: "The quick brown fox jumped over the lazy dog"
          oneOf:
            - type: string
              description: A string prompt.
              default: ""
              example: "This is a test."
            - type: array
              description: A list of string prompts.
              minItems: 1
              maxItems: 2048
              items:
                type: string
                default: ""
                example: "This is a test."
            - type: array
              description: A tokenized prompt.
              minItems: 1
              maxItems: 2048
              items:
                type: integer
              example: "[1212, 318, 257, 1332, 13]"
            - type: array
              description: A list of tokenized prompts.
              minItems: 1
              maxItems: 2048
              items:
                type: array
                minItems: 1
                items:
                  type: integer
              example: "[[1212, 318, 257, 1332, 13]]"
        encoding_format:
          title: EmbeddingEncodingFormat
          description: "The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/)."
          example: "float"
          default: "float"
          type: string
          enum: [ "float", "base64" ]
        dimensions:
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
          type: integer
          minimum: 1
        user: *end_user_param_configuration
      required:
        - model
        - input
    CreateEmbeddingResponse:
      type: object
      description: Represents an embedding vector returned by embedding endpoint.
      properties:
        data:
          type: array
          description: The list of embeddings generated by the model.
          items:
            $ref: "#/components/schemas/Embedding"
        model:
          type: string
          description: The name of the model used to generate the embedding.
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
        usage:
          $ref: "#/components/schemas/EmbeddingUsage"
      required:
        - object
        - model
        - data
        # - usage # Made nullable to support Together AI API which doesn't return this field with some models
    Embedding:
      type: object
      description: |
        Represents an embedding vector returned by embedding endpoint.
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
        embedding:
          title: EmbeddingVector
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).
          oneOf:
            - type: string
              description: The embedding vector as a base64-encoded string.
            - type: array
              description: The embedding vector as a list of floats.
              items:
                type: number
        object:
          type: string
          description: The object type, which is always "embedding".
          enum: [ embedding ]
      required:
        - index
        - object
        - embedding
    EmbeddingUsage:
      type: object
      description: The usage information for the request.
      properties:
        prompt_tokens:
          type: integer
          description: The number of tokens used by the prompt.
        total_tokens:
          type: integer
          description: The total number of tokens used by the request.
      required:
        - prompt_tokens
        - total_tokens
    CreateFineTuningJobRequest:
      type: object
      description: Request object for the Create fine-tuning job endpoint.
      properties:
        model:
          title: FineTuningModel
          description: |
            The name of the model to fine-tune. You can select one of the
            [supported models](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
          example: "gpt-3.5-turbo"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: FineTuningModels
              description: |
                Available fine-tuning models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "babbage-002", "davinci-002", "gpt-3.5-turbo" ]
        training_file:
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](https://platform.openai.com/docs/api-reference/files/upload) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
          type: string
          example: "file-abc123"
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJobHyperparameters"
        suffix:
          description: |
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
          type: string
          minLength: 1
          maxLength: 40
          default: null
          nullable: true
        validation_file:
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
          type: string
          nullable: true
          example: "file-abc123"
      required:
        - model
        - training_file
    FineTuningJob:
      type: object
      title: FineTuningJob
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
      properties:
        id:
          type: string
          description: The object identifier, which can be referenced in the API endpoints.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job was created.
        error:
          $ref: "#/components/schemas/FineTuningJobError"
        fine_tuned_model:
          type: string
          nullable: true
          description: The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.
        finished_at:
          type: integer
          nullable: true
          description: The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJobHyperparameters"
        model:
          type: string
          description: The base model that is being fine-tuned.
        object:
          type: string
          description: The object type, which is always "fine_tuning.job".
          enum: [ fine_tuning.job ]
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job.
        result_files:
          type: array
          description: The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
          items:
            type: string
            example: file-abc123
        status:
          $ref: "#/components/schemas/FineTuningJobStatus"
        trained_tokens:
          type: integer
          nullable: true
          description: The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.
        training_file:
          type: string
          description: The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
        validation_file:
          type: string
          nullable: true
          description: The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).
      required:
        - created_at
        - error
        - finished_at
        - fine_tuned_model
        - hyperparameters
        - id
        - model
        - object
        - organization_id
        - result_files
        - status
        - trained_tokens
        - training_file
        - validation_file
    FineTuningJobStatus:
      type: string
      description: The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.
      enum:
        [
          "validating_files",
          "queued",
          "running",
          "succeeded",
          "failed",
          "cancelled",
        ]
    FineTuningJobError:
      type: object
      nullable: true
      description: For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.
      properties:
        code:
          type: string
          description: A machine-readable error code.
        message:
          type: string
          description: A human-readable error message.
        param:
          type: string
          description: The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.
          nullable: true
      required:
        - code
        - message
        - param
    FineTuningJobHyperparameters:
      type: object
      description: The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for more details.
      properties:
        n_epochs:
          title: FineTuningNEpochs
          description: |
            The number of epochs to train the model for. An epoch refers to one
            full cycle through the training dataset.
          oneOf:
            - type: string
              title: FineTuningNEpochsOptions
              description: The mode for the number of epochs.
              enum: [ auto ]
            - type: integer
              description: The number of epochs to train the model for.
              minimum: 1
              maximum: 50
          default: auto
      required:
        - n_epochs
    ListPaginatedFineTuningJobsResponse:
      type: object
      description: Represents a list of fine-tuning jobs.
      properties:
        data:
          type: array
          description: The list of fine-tuning jobs.
          items:
            $ref: "#/components/schemas/FineTuningJob"
        has_more:
          type: boolean
          description: Whether there are more fine-tuning jobs to retrieve.
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
      required:
        - object
        - data
        - has_more
    ListFineTuningJobEventsResponse:
      type: object
      description: Represents a list of fine-tuning job events.
      properties:
        data:
          type: array
          description: The list of fine-tuning job events.
          items:
            $ref: "#/components/schemas/FineTuningJobEvent"
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
      required:
        - object
        - data
    FineTuningJobEvent:
      type: object
      description: Fine-tuning job event object.
      properties:
        id:
          type: string
          description: The event identifier, which can be referenced in the API endpoints.
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the event was created.
        level:
          type: string
          description: The log level of the event.
          enum: [ "info", "warn", "error" ]
        message:
          type: string
          description: The message of the event.
        object:
          type: string
          description: The object type, which is always "fine_tuning.job.event".
          enum: [ fine_tuning.job.event ]
      required:
        - id
        - object
        - created_at
        - level
        - message
    CreateImageRequest:
      type: object
      description: Request object for the Create image endpoint.
      properties:
        prompt:
          description: A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
          type: string
          example: "A cute baby sea otter"
        model:
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ImageModels
              description: |
                Available models for image generation. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "dall-e-2", "dall-e-3" ]
          default: "dall-e-2"
          example: "dall-e-3"
          nullable: true
          description: The model to use for image generation.
        n: &images_n
          type: integer
          minimum: 1
          maximum: 10
          default: 1
          example: 1
          nullable: true
          description: The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.
        quality:
          title: ImageQuality
          type: string
          enum: [ "standard", "hd" ]
          default: "standard"
          example: "standard"
          description: The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.
        response_format: &images_response_format
          title: ImageResponseFormat
          type: string
          enum: [ "url", "b64_json" ]
          default: "url"
          example: "url"
          nullable: true
          description: The format in which the generated images are returned. Must be one of `url` or `b64_json`.
        size: &images_size
          title: ImageSize
          type: string
          enum: [ "256x256", "512x512", "1024x1024", "1792x1024", "1024x1792" ]
          default: "1024x1024"
          example: "1024x1024"
          nullable: true
          description: The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.
        style:
          title: ImageStyle
          type: string
          enum: [ "vivid", "natural" ]
          default: "vivid"
          example: "vivid"
          nullable: true
          description: The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.
        user: *end_user_param_configuration
      required:
        - prompt
    ImagesResponse:
      type: object
      description: Represents a generated image returned by the images endpoint.
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the image was created.
        data:
          type: array
          description: The list of images generated by the model.
          items:
            $ref: "#/components/schemas/Image"
      required:
        - created
        - data
    Image:
      type: object
      description: Represents the url or the content of an image generated by the OpenAI API.
      properties:
        b64_json:
          type: string
          description: The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
        url:
          type: string
          description: The URL of the generated image, if `response_format` is `url` (default).
        revised_prompt:
          type: string
          description: The prompt that was used to generate the image, if there was any revision to the prompt.
    Model:
      title: Model
      description: Describes an OpenAI model offering that can be used with the API.
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: The object type, which is always "model".
          enum: [ model ]
        owned_by:
          type: string
          description: The organization that owns the model.
      required:
        - id
        - object
        - created
        - owned_by
    ListModelsResponse:
      type: object
      description: Represents a list of models returned by the List models endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always "list".
          enum: [ list ]
        data:
          type: array
          description: The list of models.
          items:
            $ref: "#/components/schemas/Model"
      required:
        - object
        - data
    DeleteModelResponse:
      type: object
      description: Represents a deleted response returned by the Delete model endpoint.
      properties:
        id:
          type: string
          description: The model identifier.
        deleted:
          type: boolean
          description: Whether the model was deleted.
        object:
          type: string
          description: The object type, which is always "model".
      required:
        - id
        - object
        - deleted
    CreateModerationRequest:
      type: object
      description: Request object for the Create moderation endpoint.
      properties:
        model:
          title: ModerationModel
          description: |
            Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.

            The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
          default: "text-moderation-latest"
          example: "text-moderation-stable"
          anyOf:
            - type: string
              description: The ID of the model to use for this request.
            - type: string
              title: ModerationModels
              description: |
                Available moderation models. Mind that the list may not be exhaustive nor up-to-date.
              enum: [ "text-moderation-latest", "text-moderation-stable" ]
        input:
          title: ModerationInput
          description: The input text to classify
          oneOf:
            - type: string
              description: A string input.
              default: ""
              example: "I want to kill them."
            - type: array
              description: A list of string inputs.
              items:
                type: string
                default: ""
                example: "I want to kill them."
      required:
        - input
    CreateModerationResponse:
      type: object
      description: Represents policy compliance report by OpenAI's content moderation model against a given input.
      properties:
        id:
          type: string
          description: The unique identifier for the moderation request.
        model:
          type: string
          description: The model used to generate the moderation results.
        results:
          type: array
          description: A list of moderation objects.
          items:
            $ref: "#/components/schemas/Moderation"
      required:
        - id
        - model
        - results
    Moderation:
      type: object
      description: Represents policy compliance report by OpenAI's content moderation model against a given input.
      properties:
        flagged:
          type: boolean
          description: Whether the content violates [OpenAI's usage policies](https://platform.openai.com/policies/usage-policies).
        categories:
          $ref: "#/components/schemas/ModerationCategories"
        category_scores:
          $ref: "#/components/schemas/ModerationCategoriesScores"
      required:
        - flagged
        - categories
        - category_scores
    ModerationCategories:
      type: object
      description: A list of the categories, and whether they are flagged or not.
      properties:
        hate:
          type: boolean
          description: Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.
        hate/threatening:
          type: boolean
          description: Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.
        harassment:
          type: boolean
          description: Content that expresses, incites, or promotes harassing language towards any target.
        harassment/threatening:
          type: boolean
          description: Harassment content that also includes violence or serious harm towards any target.
        self-harm:
          type: boolean
          description: Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.
        self-harm/intent:
          type: boolean
          description: Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.
        self-harm/instructions:
          type: boolean
          description: Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.
        sexual:
          type: boolean
          description: Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).
        sexual/minors:
          type: boolean
          description: Sexual content that includes an individual who is under 18 years old.
        violence:
          type: boolean
          description: Content that depicts death, violence, or physical injury.
        violence/graphic:
          type: boolean
          description: Content that depicts death, violence, or physical injury in graphic detail.
      required:
        - hate
        - hate/threatening
        - harassment
        - harassment/threatening
        - self-harm
        - self-harm/intent
        - self-harm/instructions
        - sexual
        - sexual/minors
        - violence
        - violence/graphic
    ModerationCategoriesScores:
      type: object
      description: A list of the categories along with their scores as predicted by model.
      properties:
        hate:
          type: number
          description: The score for the category 'hate'.
        hate/threatening:
          type: number
          description: The score for the category 'hate/threatening'.
        harassment:
          type: number
          description: The score for the category 'harassment'.
        harassment/threatening:
          type: number
          description: The score for the category 'harassment/threatening'.
        self-harm:
          type: number
          description: The score for the category 'self-harm'.
        self-harm/intent:
          type: number
          description: The score for the category 'self-harm/intent'.
        self-harm/instructions:
          type: number
          description: The score for the category 'self-harm/instructions'.
        sexual:
          type: number
          description: The score for the category 'sexual'.
        sexual/minors:
          type: number
          description: The score for the category 'sexual/minors'.
        violence:
          type: number
          description: The score for the category 'violence'.
        violence/graphic:
          type: number
          description: The score for the category 'violence/graphic'.
      required:
        - hate
        - hate/threatening
        - harassment
        - harassment/threatening
        - self-harm
        - self-harm/intent
        - self-harm/instructions
        - sexual
        - sexual/minors
        - violence
        - violence/graphic
    AssistantObject:
      type: object
      description: Represents an `assistant` that can call the model and use tools.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `assistant`.
          type: string
          enum: [ assistant ]
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was created.
          type: integer
        name:
          description: &assistant_name_param_description |
            The name of the assistant. The maximum length is 256 characters.
          type: string
          maxLength: 256
          nullable: true
        description:
          description: &assistant_description_param_description |
            The description of the assistant. The maximum length is 512 characters.
          type: string
          maxLength: 512
          nullable: true
        model:
          description: *model_description
          type: string
        instructions:
          description: &assistant_instructions_param_description |
            The system instructions that the assistant uses. The maximum length is 32768 characters.
          type: string
          maxLength: 32768
          nullable: true
        tools:
          description: &assistant_tools_param_description |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        file_ids:
          description: &assistant_file_param_description |
            A list of [file](https://platform.openai.com/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.
          default: [ ]
          type: array
          maxItems: 20
          items:
            type: string
        metadata:
          description: &metadata_description |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          type: object
          additionalProperties: true
          nullable: true
      required:
        - id
        - object
        - created_at
        - name
        - description
        - model
        - instructions
        - tools
        - file_ids
        - metadata
    CreateAssistantRequest:
      type: object
      description: Request object for the Create assistant endpoint.
      additionalProperties: false
      properties:
        model:
          description: *model_description
          anyOf:
            - type: string
              description: The ID of the model to use.
        name:
          description: *assistant_name_param_description
          type: string
          nullable: true
          maxLength: 256
        description:
          description: *assistant_description_param_description
          type: string
          nullable: true
          maxLength: 512
        instructions:
          description: *assistant_instructions_param_description
          type: string
          nullable: true
          maxLength: 32768
        tools:
          description: *assistant_tools_param_description
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        file_ids:
          description: *assistant_file_param_description
          default: [ ]
          maxItems: 20
          type: array
          items:
            type: string
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - model
    ModifyAssistantRequest:
      type: object
      description: Request object for the Modify assistant endpoint.
      additionalProperties: false
      properties:
        model:
          type: string
          description: *model_description
        name:
          description: *assistant_name_param_description
          type: string
          nullable: true
          maxLength: 256
        description:
          description: *assistant_description_param_description
          type: string
          nullable: true
          maxLength: 512
        instructions:
          description: *assistant_instructions_param_description
          type: string
          nullable: true
          maxLength: 32768
        tools:
          description: *assistant_tools_param_description
          default: [ ]
          type: array
          maxItems: 128
          items:
            $ref: "#/components/schemas/AssistantTools"
        file_ids:
          description: |
            A list of [File](https://platform.openai.com/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previosuly attached to the list but does not show up in the list, it will be deleted from the assistant.
          default: [ ]
          type: array
          maxItems: 20
          items:
            type: string
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    DeleteAssistantResponse:
      type: object
      description: Represents a deleted response returned by the Delete assistant endpoint.
      properties:
        id:
          type: string
          description: The assistant identifier.
        deleted:
          type: boolean
          description: Whether the assistant was deleted.
        object:
          type: string
          description: The object type, which is always `assistant.deleted`.
          enum: [ assistant.deleted ]
      required:
        - id
        - object
        - deleted
    ListAssistantsResponse:
      type: object
      description: Represents a list of assistants returned by the List assistants endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of assistants.
          items:
            $ref: "#/components/schemas/AssistantObject"
        first_id:
          type: string
          description: The ID of the first assistant in the list.
          example: "asst_abc123"
        last_id:
          type: string
          description: The ID of the last assistant in the list.
          example: "asst_abc456"
        has_more:
          type: boolean
          description: Whether there are more assistants to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    AssistantTools:
      type: object
      description: A tool that can be used by an assistant.
      oneOf:
        - $ref: "#/components/schemas/AssistantToolsCodeInterpreter"
        - $ref: "#/components/schemas/AssistantToolsRetrieval"
        - $ref: "#/components/schemas/AssistantToolsFunction"
      discriminator:
        propertyName: type
    AssistantToolsCodeInterpreter:
      type: object
      description: Code interpreter tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `code_interpreter`"
          default: "code_interpreter"
    AssistantToolsRetrieval:
      type: object
      description: Retrieval tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `retrieval`"
          default: "retrieval"
    AssistantToolsFunction:
      type: object
      description: Function tool
      properties:
        type:
          type: string
          description: "The type of tool being defined: `function`"
          default: "function"
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - function
    RunObject:
      type: object
      description: Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run`.
          type: string
          enum: [ "thread.run" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        thread_id:
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.
          type: string
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.
          type: string
        status:
          title: RunStatus
          description: The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.
          type: string
          enum:
            [
              "queued",
              "in_progress",
              "requires_action",
              "cancelling",
              "cancelled",
              "failed",
              "completed",
              "expired",
            ]
        required_action:
          title: RunRequiredAction
          type: object
          description: Details on the action required to continue the run. Will be `null` if no action is required.
          nullable: true
          properties:
            type:
              description: For now, this is always `submit_tool_outputs`.
              type: string
              enum: [ "submit_tool_outputs" ]
            submit_tool_outputs:
              title: RunSubmitToolOutputs
              type: object
              description: Details on the tool outputs needed for this run to continue.
              properties:
                tool_calls:
                  type: array
                  description: A list of the relevant tool calls.
                  items:
                    $ref: "#/components/schemas/RunToolCallObject"
              required:
                - tool_calls
          required:
            - type
            - submit_tool_outputs
        last_error:
          title: RunLastError
          type: object
          description: The last error associated with this run. Will be `null` if there are no errors.
          nullable: true
          properties:
            code:
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
              enum: [ "server_error", "rate_limit_exceeded" ]
            message:
              type: string
              description: A human-readable description of the error.
          required:
            - code
            - message
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          type: integer
          nullable: true
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          type: integer
          nullable: true
        model:
          description: The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          type: string
        instructions:
          description: The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          type: string
        tools:
          description: The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          default: [ ]
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        file_ids:
          description: The list of [File](https://platform.openai.com/docs/api-reference/files) IDs the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.
          default: [ ]
          type: array
          items:
            type: string
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        usage:
          $ref: "#/components/schemas/RunCompletionUsage"
      required:
        - id
        - object
        - created_at
        - thread_id
        - assistant_id
        - status
        - required_action
        - last_error
        - expires_at
        - started_at
        - cancelled_at
        - failed_at
        - completed_at
        - model
        - instructions
        - tools
        - file_ids
        - metadata
        - usage
    RunCompletionUsage:
      type: object
      description: Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      nullable: true
    CreateRunRequest:
      type: object
      description: Request object for the Create run endpoint.
      additionalProperties: false
      properties:
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
          type: string
        model:
          description: The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
          type: string
          nullable: true
        instructions:
          description: Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.
          type: string
          nullable: true
        additional_instructions:
          description: Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
          type: string
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - assistant_id
    ListRunsResponse:
      type: object
      description: Represents a list of runs returned by the List runs endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of runs.
          items:
            $ref: "#/components/schemas/RunObject"
        first_id:
          type: string
          description: The ID of the first run in the list.
          example: "run_abc123"
        last_id:
          type: string
          description: The ID of the last run in the list.
          example: "run_abc456"
        has_more:
          type: boolean
          description: Whether there are more runs to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    ModifyRunRequest:
      type: object
      description: Request object for the Modify run endpoint.
      additionalProperties: false
      properties:
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    SubmitToolOutputsRunRequest:
      type: object
      description: Request object for the Submit tool outputs to run endpoint.
      additionalProperties: false
      properties:
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          type: array
          items:
            $ref: "#/components/schemas/RunSubmitToolOutput"
      required:
        - tool_outputs
    RunSubmitToolOutput:
      type: object
      description: Output of a tool.
      properties:
        tool_call_id:
          type: string
          description: The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
        output:
          type: string
          description: The output of the tool call to be submitted to continue the run.
    RunToolCallObject:
      type: object
      description: Tool call objects
      properties:
        id:
          type: string
          description: The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.
        type:
          type: string
          description: The type of tool call the output is required for. For now, this is always `function`.
          enum: [ "function" ]
        function:
          type: object
          title: RunToolCallFunction
          description: The function definition.
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments that the model expects you to pass to the function.
          required:
            - name
            - arguments
      required:
        - id
        - type
        - function
    CreateThreadAndRunRequest:
      type: object
      description: Request object for the Create thread and run endpoint.
      additionalProperties: false
      properties:
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
          type: string
        thread:
          $ref: "#/components/schemas/CreateThreadRequest"
          description: If no thread is provided, an empty thread will be created.
        model:
          description: The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
          type: string
          nullable: true
        instructions:
          description: Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
          type: string
          nullable: true
        tools:
          description: Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: array
          maxItems: 20
          items:
            $ref: "#/components/schemas/AssistantTools"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - assistant_id
    ThreadObject:
      type: object
      description: Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread`.
          type: string
          enum: [ "thread" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - id
        - object
        - created_at
        - metadata
    CreateThreadRequest:
      type: object
      description: Request object for the Create thread endpoint.
      additionalProperties: false
      properties:
        messages:
          description: A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.
          type: array
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    ModifyThreadRequest:
      type: object
      description: Request object for the Modify thread endpoint.
      additionalProperties: false
      properties:
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    DeleteThreadResponse:
      type: object
      properties:
        id:
          type: string
          description: The thread identifier.
        deleted:
          type: boolean
          description: Whether the thread was deleted.
        object:
          type: string
          description: The object type, which is always `thread.deleted`.
          enum: [ thread.deleted ]
      required:
        - id
        - object
        - deleted
    ListThreadsResponse:
      type: object
      description: Represents a list of threads returned by the List threads endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of threads.
          items:
            $ref: "#/components/schemas/ThreadObject"
        first_id:
          type: string
          description: The ID of the first thread in the list.
          example: "asst_hLBK7PXBv5Lr2NQT7KLY0ag1"
        last_id:
          type: string
          description: The ID of the last thread in the list.
          example: "asst_QLoItBbqwyAJEzlTy4y9kOMM"
        has_more:
          type: boolean
          description: Whether there are more threads to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    MessageObject:
      type: object
      description: Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.message`.
          type: string
          enum: [ "thread.message" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        thread_id:
          description: The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.
          type: string
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          type: string
          enum: [ "user", "assistant" ]
        content:
          description: The content of the message in array of text and/or images.
          type: array
          items:
            $ref: "#/components/schemas/MessageContent"
        assistant_id:
          description: If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.
          type: string
          nullable: true
        run_id:
          description: If applicable, the ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the authoring of this message.
          type: string
          nullable: true
        file_ids:
          description: A list of [file](https://platform.openai.com/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be attached to a message.
          default: [ ]
          maxItems: 10
          type: array
          items:
            type: string
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
      required:
        - id
        - object
        - created_at
        - thread_id
        - role
        - content
        - assistant_id
        - run_id
        - file_ids
        - metadata
    MessageContent:
      type: object
      description: The content of a message.
      oneOf:
        - $ref: "#/components/schemas/MessageContentImageFileObject"
        - $ref: "#/components/schemas/MessageContentTextObject"
      discriminator:
        propertyName: type
    CreateMessageRequest:
      type: object
      description: Request object for the Create message endpoint.
      additionalProperties: false
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [ "user" ]
          description: The role of the entity that is creating the message. Currently only `user` is supported.
        content:
          type: string
          minLength: 1
          maxLength: 32768
          description: The content of the message.
        file_ids:
          description: A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.
          default: [ ]
          type: array
          minItems: 1
          maxItems: 10
          items:
            type: string
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    ModifyMessageRequest:
      type: object
      description: Request object for the Modify message endpoint.
      additionalProperties: false
      properties:
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
    DeleteMessageResponse:
      type: object
      properties:
        id:
          type: string
          description: The message identifier.
        deleted:
          type: boolean
          description: Whether the message was deleted.
        object:
          type: string
          description: The object type, which is always `thread.message.deleted`.
          enum: [ thread.message.deleted ]
      required:
        - id
        - object
        - deleted
    ListMessagesResponse:
      type: object
      description: Represents a list of messages returned by the List messages endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of messages.
          items:
            $ref: "#/components/schemas/MessageObject"
        first_id:
          type: string
          description: The ID of the first message in the list.
          example: "msg_abc123"
        last_id:
          type: string
          description: The ID of the last message in the list.
          example: "msg_abc123"
        has_more:
          type: boolean
          description: Whether there are more messages to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    MessageContentImageFileObject:
      type: object
      description: References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.
      properties:
        type:
          description: Always `image_file`.
          type: string
        image_file:
          $ref: "#/components/schemas/MessageContentImageFile"
      required:
        - type
        - image_file
    MessageContentImageFile:
      type: object
      description: The image file that is part of a message.
      properties:
        file_id:
          description: The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content.
          type: string
      required:
        - file_id
    MessageContentTextObject:
      type: object
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          type: string
        text:
          $ref: "#/components/schemas/MessageContentText"
      required:
        - type
        - text
    MessageContentText:
      type: object
      description: The text content that is part of a message.
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          type: array
          description: A list of annotations that point to specific quotes from specific files.
          items:
            $ref: "#/components/schemas/MessageContentTextAnnotations"
      required:
        - value
        - annotations
    MessageContentTextAnnotations:
      type: object
      description: An annotation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      oneOf:
        - $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject"
        - $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject"
    MessageContentTextAnnotationsFileCitationObject:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "retrieval" tool to search files.
      properties:
        type:
          description: Always `file_citation`.
          type: string
          enum: [ "file_citation" ]
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitation"
        start_index:
          type: integer
          description: The start index of the text in the message content that needs to be replaced.
          minimum: 0
        end_index:
          type: integer
          description: The end index of the text in the message content that needs to be replaced.
          minimum: 0
      required:
        - type
        - text
        - file_citation
        - start_index
        - end_index
    MessageContentTextAnnotationsFileCitation:
      type: object
      description: A citation within the message that points to a specific quote from a specific File associated with the assistant or the message.
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
      required:
        - file_id
        - quote
    MessageContentTextAnnotationsFilePathObject:
      type: object
      description: A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file.
      properties:
        type:
          description: Always `file_path`.
          type: string
          enum: [ "file_path" ]
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          type: object
          title: MessageContentTextAnnotationsFilePath
          properties:
            file_id:
              description: The ID of the file that was generated.
              type: string
          required:
            - file_id
        start_index:
          type: integer
          minimum: 0
        end_index:
          type: integer
          minimum: 0
      required:
        - type
        - text
        - file_path
        - start_index
        - end_index
    RunStepObject:
      type: object
      description: |
        Represents a step in execution of a run.
      properties:
        id:
          description: The identifier of the run step, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run.step`.
          type: string
          enum: [ "thread.run.step" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        assistant_id:
          description: The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) associated with the run step.
          type: string
        thread_id:
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
          type: string
        run_id:
          description: The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that this run step is a part of.
          type: string
        type:
          description: The type of run step, which can be either `message_creation` or `tool_calls`.
          type: string
          title: RunStepType
          enum: [ "message_creation", "tool_calls" ]
        status:
          description: The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.
          type: string
          title: RunStepStatus
          enum: [ "in_progress", "cancelled", "failed", "completed", "expired" ]
        step_details:
          $ref: "#/components/schemas/RunStepDetails"
        last_error:
          type: object
          title: RunStepLastError
          description: The last error associated with this run step. Will be `null` if there are no errors.
          nullable: true
          properties:
            code:
              type: string
              description: One of `server_error` or `rate_limit_exceeded`.
              enum: [ "server_error", "rate_limit_exceeded" ]
            message:
              type: string
              description: A human-readable description of the error.
          required:
            - code
            - message
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.
          type: integer
          nullable: true
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          type: integer
          nullable: true
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          type: integer
          nullable: true
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          type: integer
          nullable: true
        metadata:
          description: *metadata_description
          type: object
          additionalProperties: true
          nullable: true
        usage:
          $ref: "#/components/schemas/RunStepCompletionUsage"
      required:
        - id
        - object
        - created_at
        - assistant_id
        - thread_id
        - run_id
        - type
        - status
        - step_details
        - last_error
        - expired_at
        - cancelled_at
        - failed_at
        - completed_at
        - metadata
        - usage
    RunStepDetails:
      type: object
      description: The details of the run step.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsMessageCreationObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsObject"
    ListRunStepsResponse:
      type: object
      description: Represents a list of run steps returned by the List run steps endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: The list of run steps.
          items:
            $ref: "#/components/schemas/RunStepObject"
        first_id:
          type: string
          description: The ID of the first run step in the list.
          example: "step_abc123"
        last_id:
          type: string
          description: The ID of the last run step in the list.
          example: "step_abc456"
        has_more:
          type: boolean
          description: Whether there are more run steps to retrieve.
          example: false
      required:
        - object
        - data
        - first_id
        - last_id
        - has_more
    RunStepDetailsMessageCreationObject:
      type: object
      description: Details of the message creation by the run step.
      properties:
        type:
          description: Always `message_creation`.
          type: string
          enum: [ "message_creation" ]
        message_creation:
          $ref: "#/components/schemas/RunStepDetailsMessageCreation"
      required:
        - type
        - message_creation
    RunStepDetailsMessageCreation:
      type: object
      description: Details of the message creation by the run step.
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step.
      required:
        - message_id
    RunStepDetailsToolCallsObject:
      type: object
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          type: string
          enum: [ "tool_calls" ]
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `retrieval`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCalls"
      required:
        - type
        - tool_calls
    RunStepDetailsToolCalls:
      type: object
      description: Tool calls the run step was involved in.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsRetrievalObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject"
    RunStepDetailsToolCallsCodeObject:
      type: object
      description: Details of the Code Interpreter tool call the run step was involved in.
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          description: The type of tool call. This is always going to be `code_interpreter` for this type of tool call.
          enum: [ "code_interpreter" ]
        code_interpreter:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreter"
      required:
        - id
        - type
        - code_interpreter
    RunStepDetailsToolCallsCodeObjectCodeInterpreter:
      type: object
      description: The Code Interpreter tool call definition.
      required:
        - input
        - outputs
      properties:
        input:
          type: string
          description: The input to the Code Interpreter tool call.
        outputs:
          type: array
          description: The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutput"
    RunStepDetailsToolCallsCodeOutput:
      type: object
      description: The output of the Code Interpreter tool call.
      oneOf:
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject"
        - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject"
    RunStepDetailsToolCallsCodeOutputLogsObject:
      type: object
      description: Text output from the Code Interpreter tool call as part of a run step.
      properties:
        type:
          description: Always `logs`.
          type: string
          enum: [ "logs" ]
        logs:
          type: string
          description: The text output from the Code Interpreter tool call.
      required:
        - type
        - logs
    RunStepDetailsToolCallsCodeOutputImageObject:
      type: object
      description: Code interpreter image output
      properties:
        type:
          description: Always `image`.
          type: string
          enum: [ "image" ]
        image:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImage"
      required:
        - type
        - image
    RunStepDetailsToolCallsCodeOutputImage:
      type: object
      description: Code interpreter image output.
      properties:
        file_id:
          description: The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.
          type: string
      required:
        - file_id
    RunStepDetailsToolCallsRetrievalObject:
      description: Retrieval tool call
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: The type of tool call. This is always going to be `retrieval` for this type of tool call.
          enum: [ "retrieval" ]
        retrieval:
          type: object
          description: For now, this is always going to be an empty object.
          additionalProperties: true
      required:
        - id
        - type
        - retrieval
    RunStepDetailsToolCallsFunctionObject:
      type: object
      description: Function tool call
      properties:
        id:
          type: string
          description: The ID of the tool call object.
        type:
          type: string
          description: The type of tool call. This is always going to be `function` for this type of tool call.
          enum: [ "function" ]
        function:
          type: object
          title: RunStepDetailsToolCallsFunction
          description: The definition of the function that was called.
          properties:
            name:
              type: string
              description: The name of the function.
            arguments:
              type: string
              description: The arguments passed to the function.
            output:
              type: string
              description: The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.
              nullable: true
          required:
            - name
            - arguments
            - output
      required:
        - id
        - type
        - function
    RunStepCompletionUsage:
      type: object
      description: Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run step.
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step.
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion).
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      nullable: true
    AssistantFileObject:
      type: object
      description: A list of [Files](https://platform.openai.com/docs/api-reference/files) attached to an `assistant`.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `assistant.file`.
          type: string
          enum: [ assistant.file ]
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant file was created.
          type: integer
        assistant_id:
          description: The assistant ID that the file is attached to.
          type: string
      required:
        - id
        - object
        - created_at
        - assistant_id
    CreateAssistantFileRequest:
      type: object
      description: Request object for the Create assistant file endpoint.
      additionalProperties: false
      properties:
        file_id:
          description: A [File](https://platform.openai.com/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.
          type: string
      required:
        - file_id
    DeleteAssistantFileResponse:
      type: object
      description: Deletes the association between the assistant and the file, but does not delete the [File](https://platform.openai.com/docs/api-reference/files) object itself.
      properties:
        id:
          type: string
          description: The ID of the assistant file.
        deleted:
          type: boolean
          description: Whether the assistant file was deleted.
        object:
          type: string
          description: The object type, which is always `assistant.file.deleted`.
          enum: [ assistant.file.deleted ]
      required:
        - id
        - object
        - deleted
    ListAssistantFilesResponse:
      type: object
      description: Represents a list of assistant files returned by the List assistant files endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: A list of assistant files.
          items:
            $ref: "#/components/schemas/AssistantFileObject"
        first_id:
          type: string
          description: The ID of the first assistant file in the list.
          example: "file-abc123"
        last_id:
          type: string
          description: The ID of the last assistant file in the list.
          example: "file-abc456"
        has_more:
          type: boolean
          description: Whether there are more assistant files available.
          example: false
      required:
        - object
        - data
        - items
        - first_id
        - last_id
        - has_more
    MessageFileObject:
      type: object
      description: A list of files attached to a `message`.
      properties:
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.message.file`.
          type: string
          enum: [ "thread.message.file" ]
        created_at:
          description: The Unix timestamp (in seconds) for when the message file was created.
          type: integer
        message_id:
          description: The ID of the [message](https://platform.openai.com/docs/api-reference/messages) that the [File](https://platform.openai.com/docs/api-reference/files) is attached to.
          type: string
      required:
        - id
        - object
        - created_at
        - message_id
    ListMessageFilesResponse:
      type: object
      description: Represents a list of message files returned by the List message files endpoint.
      properties:
        object:
          type: string
          description: The object type, which is always `list`.
          example: "list"
        data:
          type: array
          description: A list of message files.
          items:
            $ref: "#/components/schemas/MessageFileObject"
        first_id:
          type: string
          description: The ID of the first message file in the list.
          example: "file-abc123"
        last_id:
          type: string
          description: The ID of the last message file in the list.
          example: "file-abc456"
        has_more:
          type: boolean
          description: Whether there are more message files available.
          example: false
      required:
        - object
        - data
        - items
        - first_id
        - last_id
        - has_more

security:
  - ApiKeyAuth: [ ]
